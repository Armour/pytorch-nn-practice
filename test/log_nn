==> Init variables..
==> Init seed..
==> Download data..
Files already downloaded and verified
==> Calculate mean and std..
==> Prepare training transform..
==> Prepare testing transform..
==> Init dataloader..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
==> Set learning rate: 0.010000
==> Training Epoch: 0
0.000000/1000.000000 ==> Training loss: 5.029391    Training error rate: 100.000000
50.000000/1000.000000 ==> Training loss: 4.898141    Training error rate: 98.000000
100.000000/1000.000000 ==> Training loss: 4.361096    Training error rate: 92.000000
150.000000/1000.000000 ==> Training loss: 4.216114    Training error rate: 94.000000
200.000000/1000.000000 ==> Training loss: 4.161497    Training error rate: 92.000000
250.000000/1000.000000 ==> Training loss: 4.184125    Training error rate: 88.000000
300.000000/1000.000000 ==> Training loss: 4.015401    Training error rate: 94.000000
350.000000/1000.000000 ==> Training loss: 3.769460    Training error rate: 88.000000
400.000000/1000.000000 ==> Training loss: 3.842850    Training error rate: 86.000000
450.000000/1000.000000 ==> Training loss: 3.953154    Training error rate: 94.000000
500.000000/1000.000000 ==> Training loss: 3.799273    Training error rate: 90.000000
550.000000/1000.000000 ==> Training loss: 4.298512    Training error rate: 94.000000
600.000000/1000.000000 ==> Training loss: 3.518184    Training error rate: 84.000000
650.000000/1000.000000 ==> Training loss: 3.584412    Training error rate: 94.000000
700.000000/1000.000000 ==> Training loss: 3.824395    Training error rate: 88.000000
750.000000/1000.000000 ==> Training loss: 3.542033    Training error rate: 84.000000
800.000000/1000.000000 ==> Training loss: 3.812072    Training error rate: 88.000000
850.000000/1000.000000 ==> Training loss: 3.358830    Training error rate: 86.000000
900.000000/1000.000000 ==> Training loss: 3.563442    Training error rate: 86.000000
950.000000/1000.000000 ==> Training loss: 3.395255    Training error rate: 88.000000
==> Total training loss: 3931.522740    Total training error rate: 90.416000
==> Testing Epoch: 0
0.000000/100.000000 ==> Testing loss: 3.708316    Testing error rate: 85.000000
50.000000/100.000000 ==> Testing loss: 3.558834    Testing error rate: 82.000000
==> Total testing loss: 360.122610    Total testing error rate: 85.590000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 1
0.000000/1000.000000 ==> Training loss: 3.851270    Training error rate: 88.000000
50.000000/1000.000000 ==> Training loss: 3.366187    Training error rate: 80.000000
100.000000/1000.000000 ==> Training loss: 3.511230    Training error rate: 82.000000
150.000000/1000.000000 ==> Training loss: 3.224579    Training error rate: 76.000000
200.000000/1000.000000 ==> Training loss: 3.573780    Training error rate: 90.000000
250.000000/1000.000000 ==> Training loss: 3.403411    Training error rate: 82.000000
300.000000/1000.000000 ==> Training loss: 2.990500    Training error rate: 70.000000
350.000000/1000.000000 ==> Training loss: 3.374107    Training error rate: 78.000000
400.000000/1000.000000 ==> Training loss: 3.423450    Training error rate: 74.000000
450.000000/1000.000000 ==> Training loss: 3.377571    Training error rate: 88.000000
500.000000/1000.000000 ==> Training loss: 3.710706    Training error rate: 80.000000
550.000000/1000.000000 ==> Training loss: 3.201613    Training error rate: 80.000000
600.000000/1000.000000 ==> Training loss: 3.370976    Training error rate: 82.000000
650.000000/1000.000000 ==> Training loss: 3.576585    Training error rate: 86.000000
700.000000/1000.000000 ==> Training loss: 2.999056    Training error rate: 82.000000
750.000000/1000.000000 ==> Training loss: 2.714272    Training error rate: 66.000000
800.000000/1000.000000 ==> Training loss: 3.025952    Training error rate: 80.000000
850.000000/1000.000000 ==> Training loss: 3.040549    Training error rate: 76.000000
900.000000/1000.000000 ==> Training loss: 3.242369    Training error rate: 84.000000
950.000000/1000.000000 ==> Training loss: 2.928153    Training error rate: 72.000000
==> Total training loss: 3259.684257    Total training error rate: 79.970000
==> Testing Epoch: 1
0.000000/100.000000 ==> Testing loss: 2.934386    Testing error rate: 72.000000
50.000000/100.000000 ==> Testing loss: 2.898133    Testing error rate: 66.000000
==> Total testing loss: 303.869998    Total testing error rate: 75.060000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 2
0.000000/1000.000000 ==> Training loss: 3.134021    Training error rate: 80.000000
50.000000/1000.000000 ==> Training loss: 2.772020    Training error rate: 72.000000
100.000000/1000.000000 ==> Training loss: 3.149623    Training error rate: 76.000000
150.000000/1000.000000 ==> Training loss: 2.811282    Training error rate: 72.000000
200.000000/1000.000000 ==> Training loss: 2.759930    Training error rate: 64.000000
250.000000/1000.000000 ==> Training loss: 2.411097    Training error rate: 74.000000
300.000000/1000.000000 ==> Training loss: 3.190431    Training error rate: 72.000000
350.000000/1000.000000 ==> Training loss: 3.143771    Training error rate: 84.000000
400.000000/1000.000000 ==> Training loss: 3.090776    Training error rate: 76.000000
450.000000/1000.000000 ==> Training loss: 3.056757    Training error rate: 74.000000
500.000000/1000.000000 ==> Training loss: 3.003339    Training error rate: 76.000000
550.000000/1000.000000 ==> Training loss: 3.040846    Training error rate: 72.000000
600.000000/1000.000000 ==> Training loss: 2.867887    Training error rate: 82.000000
650.000000/1000.000000 ==> Training loss: 2.773387    Training error rate: 72.000000
700.000000/1000.000000 ==> Training loss: 2.573184    Training error rate: 70.000000
750.000000/1000.000000 ==> Training loss: 2.589267    Training error rate: 66.000000
800.000000/1000.000000 ==> Training loss: 2.897901    Training error rate: 80.000000
850.000000/1000.000000 ==> Training loss: 2.794267    Training error rate: 74.000000
900.000000/1000.000000 ==> Training loss: 2.653901    Training error rate: 72.000000
950.000000/1000.000000 ==> Training loss: 2.889893    Training error rate: 66.000000
==> Total training loss: 2777.658551    Total training error rate: 71.046000
==> Testing Epoch: 2
0.000000/100.000000 ==> Testing loss: 2.603648    Testing error rate: 67.000000
50.000000/100.000000 ==> Testing loss: 2.605113    Testing error rate: 59.000000
==> Total testing loss: 267.703099    Total testing error rate: 67.750000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 3
0.000000/1000.000000 ==> Training loss: 2.560756    Training error rate: 66.000000
50.000000/1000.000000 ==> Training loss: 2.548858    Training error rate: 70.000000
100.000000/1000.000000 ==> Training loss: 2.553410    Training error rate: 66.000000
150.000000/1000.000000 ==> Training loss: 2.192819    Training error rate: 64.000000
200.000000/1000.000000 ==> Training loss: 2.604658    Training error rate: 68.000000
250.000000/1000.000000 ==> Training loss: 2.744165    Training error rate: 68.000000
300.000000/1000.000000 ==> Training loss: 2.451222    Training error rate: 66.000000
350.000000/1000.000000 ==> Training loss: 2.629852    Training error rate: 76.000000
400.000000/1000.000000 ==> Training loss: 2.558078    Training error rate: 68.000000
450.000000/1000.000000 ==> Training loss: 2.728191    Training error rate: 76.000000
500.000000/1000.000000 ==> Training loss: 1.914828    Training error rate: 48.000000
550.000000/1000.000000 ==> Training loss: 2.477101    Training error rate: 68.000000
600.000000/1000.000000 ==> Training loss: 1.943441    Training error rate: 56.000000
650.000000/1000.000000 ==> Training loss: 2.283140    Training error rate: 64.000000
700.000000/1000.000000 ==> Training loss: 2.677482    Training error rate: 62.000000
750.000000/1000.000000 ==> Training loss: 1.867966    Training error rate: 54.000000
800.000000/1000.000000 ==> Training loss: 2.502743    Training error rate: 68.000000
850.000000/1000.000000 ==> Training loss: 2.311512    Training error rate: 62.000000
900.000000/1000.000000 ==> Training loss: 2.141321    Training error rate: 48.000000
950.000000/1000.000000 ==> Training loss: 2.165891    Training error rate: 54.000000
==> Total training loss: 2373.863343    Total training error rate: 62.542000
==> Testing Epoch: 3
0.000000/100.000000 ==> Testing loss: 2.487535    Testing error rate: 65.000000
50.000000/100.000000 ==> Testing loss: 2.299302    Testing error rate: 60.000000
==> Total testing loss: 247.161692    Total testing error rate: 62.760000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 4
0.000000/1000.000000 ==> Training loss: 1.892125    Training error rate: 44.000000
50.000000/1000.000000 ==> Training loss: 2.164259    Training error rate: 56.000000
100.000000/1000.000000 ==> Training loss: 2.441503    Training error rate: 66.000000
150.000000/1000.000000 ==> Training loss: 2.132120    Training error rate: 62.000000
200.000000/1000.000000 ==> Training loss: 1.841304    Training error rate: 40.000000
250.000000/1000.000000 ==> Training loss: 2.247888    Training error rate: 68.000000
300.000000/1000.000000 ==> Training loss: 2.569627    Training error rate: 68.000000
350.000000/1000.000000 ==> Training loss: 2.286405    Training error rate: 64.000000
400.000000/1000.000000 ==> Training loss: 2.081569    Training error rate: 52.000000
450.000000/1000.000000 ==> Training loss: 2.626371    Training error rate: 72.000000
500.000000/1000.000000 ==> Training loss: 2.197499    Training error rate: 62.000000
550.000000/1000.000000 ==> Training loss: 2.217367    Training error rate: 56.000000
600.000000/1000.000000 ==> Training loss: 2.379822    Training error rate: 58.000000
650.000000/1000.000000 ==> Training loss: 1.763310    Training error rate: 44.000000
700.000000/1000.000000 ==> Training loss: 1.875010    Training error rate: 54.000000
750.000000/1000.000000 ==> Training loss: 2.164322    Training error rate: 64.000000
800.000000/1000.000000 ==> Training loss: 2.049437    Training error rate: 58.000000
850.000000/1000.000000 ==> Training loss: 1.568239    Training error rate: 42.000000
900.000000/1000.000000 ==> Training loss: 2.272030    Training error rate: 64.000000
950.000000/1000.000000 ==> Training loss: 2.235667    Training error rate: 56.000000
==> Total training loss: 2090.034345    Total training error rate: 56.582000
==> Testing Epoch: 4
0.000000/100.000000 ==> Testing loss: 2.000209    Testing error rate: 53.000000
50.000000/100.000000 ==> Testing loss: 1.905895    Testing error rate: 50.000000
==> Total testing loss: 197.824349    Total testing error rate: 53.320000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 5
0.000000/1000.000000 ==> Training loss: 1.955549    Training error rate: 58.000000
50.000000/1000.000000 ==> Training loss: 2.007294    Training error rate: 56.000000
100.000000/1000.000000 ==> Training loss: 1.757735    Training error rate: 56.000000
150.000000/1000.000000 ==> Training loss: 1.622085    Training error rate: 46.000000
200.000000/1000.000000 ==> Training loss: 2.025647    Training error rate: 64.000000
250.000000/1000.000000 ==> Training loss: 1.759214    Training error rate: 50.000000
300.000000/1000.000000 ==> Training loss: 1.756608    Training error rate: 52.000000
350.000000/1000.000000 ==> Training loss: 2.317812    Training error rate: 56.000000
400.000000/1000.000000 ==> Training loss: 2.105532    Training error rate: 56.000000
450.000000/1000.000000 ==> Training loss: 2.012597    Training error rate: 46.000000
500.000000/1000.000000 ==> Training loss: 1.616798    Training error rate: 46.000000
550.000000/1000.000000 ==> Training loss: 1.908335    Training error rate: 60.000000
600.000000/1000.000000 ==> Training loss: 1.755300    Training error rate: 42.000000
650.000000/1000.000000 ==> Training loss: 1.768600    Training error rate: 52.000000
700.000000/1000.000000 ==> Training loss: 2.396372    Training error rate: 72.000000
750.000000/1000.000000 ==> Training loss: 1.660931    Training error rate: 54.000000
800.000000/1000.000000 ==> Training loss: 1.820891    Training error rate: 52.000000
850.000000/1000.000000 ==> Training loss: 2.021581    Training error rate: 58.000000
900.000000/1000.000000 ==> Training loss: 2.038314    Training error rate: 50.000000
950.000000/1000.000000 ==> Training loss: 2.223266    Training error rate: 50.000000
==> Total training loss: 1874.286453    Total training error rate: 51.716000
==> Testing Epoch: 5
0.000000/100.000000 ==> Testing loss: 2.037953    Testing error rate: 48.000000
50.000000/100.000000 ==> Testing loss: 1.841476    Testing error rate: 52.000000
==> Total testing loss: 197.332585    Total testing error rate: 52.880000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 6
0.000000/1000.000000 ==> Training loss: 1.560568    Training error rate: 42.000000
50.000000/1000.000000 ==> Training loss: 1.662123    Training error rate: 52.000000
100.000000/1000.000000 ==> Training loss: 1.959139    Training error rate: 50.000000
150.000000/1000.000000 ==> Training loss: 1.835733    Training error rate: 50.000000
200.000000/1000.000000 ==> Training loss: 1.836431    Training error rate: 56.000000
250.000000/1000.000000 ==> Training loss: 1.519965    Training error rate: 40.000000
300.000000/1000.000000 ==> Training loss: 1.439785    Training error rate: 36.000000
350.000000/1000.000000 ==> Training loss: 1.989358    Training error rate: 54.000000
400.000000/1000.000000 ==> Training loss: 1.549448    Training error rate: 46.000000
450.000000/1000.000000 ==> Training loss: 1.649699    Training error rate: 52.000000
500.000000/1000.000000 ==> Training loss: 1.607680    Training error rate: 40.000000
550.000000/1000.000000 ==> Training loss: 1.705264    Training error rate: 44.000000
600.000000/1000.000000 ==> Training loss: 1.977044    Training error rate: 50.000000
650.000000/1000.000000 ==> Training loss: 1.571573    Training error rate: 48.000000
700.000000/1000.000000 ==> Training loss: 1.747988    Training error rate: 46.000000
750.000000/1000.000000 ==> Training loss: 1.814120    Training error rate: 46.000000
800.000000/1000.000000 ==> Training loss: 1.286510    Training error rate: 36.000000
850.000000/1000.000000 ==> Training loss: 1.369557    Training error rate: 36.000000
900.000000/1000.000000 ==> Training loss: 1.897374    Training error rate: 50.000000
950.000000/1000.000000 ==> Training loss: 1.617844    Training error rate: 46.000000
==> Total training loss: 1696.844398    Total training error rate: 47.752000
==> Testing Epoch: 6
0.000000/100.000000 ==> Testing loss: 1.975407    Testing error rate: 50.000000
50.000000/100.000000 ==> Testing loss: 1.673123    Testing error rate: 44.000000
==> Total testing loss: 189.612450    Total testing error rate: 50.680000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 7
0.000000/1000.000000 ==> Training loss: 1.299728    Training error rate: 40.000000
50.000000/1000.000000 ==> Training loss: 1.700771    Training error rate: 44.000000
100.000000/1000.000000 ==> Training loss: 1.397568    Training error rate: 38.000000
150.000000/1000.000000 ==> Training loss: 1.530709    Training error rate: 50.000000
200.000000/1000.000000 ==> Training loss: 1.955656    Training error rate: 56.000000
250.000000/1000.000000 ==> Training loss: 1.582182    Training error rate: 44.000000
300.000000/1000.000000 ==> Training loss: 1.659953    Training error rate: 46.000000
350.000000/1000.000000 ==> Training loss: 1.468449    Training error rate: 34.000000
400.000000/1000.000000 ==> Training loss: 1.627402    Training error rate: 46.000000
450.000000/1000.000000 ==> Training loss: 1.467229    Training error rate: 48.000000
500.000000/1000.000000 ==> Training loss: 1.676443    Training error rate: 46.000000
550.000000/1000.000000 ==> Training loss: 1.513354    Training error rate: 48.000000
600.000000/1000.000000 ==> Training loss: 1.353606    Training error rate: 42.000000
650.000000/1000.000000 ==> Training loss: 1.444986    Training error rate: 40.000000
700.000000/1000.000000 ==> Training loss: 1.392366    Training error rate: 42.000000
750.000000/1000.000000 ==> Training loss: 1.515343    Training error rate: 40.000000
800.000000/1000.000000 ==> Training loss: 1.961533    Training error rate: 56.000000
850.000000/1000.000000 ==> Training loss: 1.587612    Training error rate: 42.000000
900.000000/1000.000000 ==> Training loss: 1.537948    Training error rate: 46.000000
950.000000/1000.000000 ==> Training loss: 1.337864    Training error rate: 36.000000
==> Total training loss: 1554.583035    Total training error rate: 44.020000
==> Testing Epoch: 7
0.000000/100.000000 ==> Testing loss: 1.935714    Testing error rate: 50.000000
50.000000/100.000000 ==> Testing loss: 1.498611    Testing error rate: 43.000000
==> Total testing loss: 169.945757    Total testing error rate: 47.420000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 8
0.000000/1000.000000 ==> Training loss: 1.150172    Training error rate: 34.000000
50.000000/1000.000000 ==> Training loss: 1.612173    Training error rate: 46.000000
100.000000/1000.000000 ==> Training loss: 1.376992    Training error rate: 40.000000
150.000000/1000.000000 ==> Training loss: 1.914713    Training error rate: 62.000000
200.000000/1000.000000 ==> Training loss: 1.353400    Training error rate: 34.000000
250.000000/1000.000000 ==> Training loss: 1.824779    Training error rate: 50.000000
300.000000/1000.000000 ==> Training loss: 1.531758    Training error rate: 44.000000
350.000000/1000.000000 ==> Training loss: 1.395889    Training error rate: 40.000000
400.000000/1000.000000 ==> Training loss: 1.145890    Training error rate: 30.000000
450.000000/1000.000000 ==> Training loss: 1.401190    Training error rate: 42.000000
500.000000/1000.000000 ==> Training loss: 1.392038    Training error rate: 38.000000
550.000000/1000.000000 ==> Training loss: 1.406350    Training error rate: 32.000000
600.000000/1000.000000 ==> Training loss: 1.175570    Training error rate: 28.000000
650.000000/1000.000000 ==> Training loss: 1.753520    Training error rate: 54.000000
700.000000/1000.000000 ==> Training loss: 1.651298    Training error rate: 48.000000
750.000000/1000.000000 ==> Training loss: 1.324146    Training error rate: 42.000000
800.000000/1000.000000 ==> Training loss: 1.449450    Training error rate: 36.000000
850.000000/1000.000000 ==> Training loss: 1.624932    Training error rate: 46.000000
900.000000/1000.000000 ==> Training loss: 1.134698    Training error rate: 36.000000
950.000000/1000.000000 ==> Training loss: 1.137368    Training error rate: 32.000000
==> Total training loss: 1446.487852    Total training error rate: 41.458000
==> Testing Epoch: 8
0.000000/100.000000 ==> Testing loss: 1.512397    Testing error rate: 41.000000
50.000000/100.000000 ==> Testing loss: 1.467429    Testing error rate: 43.000000
==> Total testing loss: 169.503910    Total testing error rate: 46.300000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 9
0.000000/1000.000000 ==> Training loss: 1.447400    Training error rate: 42.000000
50.000000/1000.000000 ==> Training loss: 1.218250    Training error rate: 34.000000
100.000000/1000.000000 ==> Training loss: 1.439195    Training error rate: 38.000000
150.000000/1000.000000 ==> Training loss: 1.379874    Training error rate: 38.000000
200.000000/1000.000000 ==> Training loss: 1.152457    Training error rate: 44.000000
250.000000/1000.000000 ==> Training loss: 1.246386    Training error rate: 34.000000
300.000000/1000.000000 ==> Training loss: 1.499922    Training error rate: 42.000000
350.000000/1000.000000 ==> Training loss: 1.367169    Training error rate: 34.000000
400.000000/1000.000000 ==> Training loss: 1.343512    Training error rate: 32.000000
450.000000/1000.000000 ==> Training loss: 1.564186    Training error rate: 50.000000
500.000000/1000.000000 ==> Training loss: 1.371877    Training error rate: 42.000000
550.000000/1000.000000 ==> Training loss: 1.640230    Training error rate: 50.000000
600.000000/1000.000000 ==> Training loss: 1.137396    Training error rate: 38.000000
650.000000/1000.000000 ==> Training loss: 1.457500    Training error rate: 44.000000
700.000000/1000.000000 ==> Training loss: 1.515036    Training error rate: 44.000000
750.000000/1000.000000 ==> Training loss: 1.657822    Training error rate: 52.000000
800.000000/1000.000000 ==> Training loss: 1.232557    Training error rate: 38.000000
850.000000/1000.000000 ==> Training loss: 1.228549    Training error rate: 38.000000
900.000000/1000.000000 ==> Training loss: 1.152247    Training error rate: 32.000000
950.000000/1000.000000 ==> Training loss: 1.174602    Training error rate: 26.000000
==> Total training loss: 1353.825752    Total training error rate: 39.134000
==> Testing Epoch: 9
0.000000/100.000000 ==> Testing loss: 1.503672    Testing error rate: 42.000000
50.000000/100.000000 ==> Testing loss: 1.322242    Testing error rate: 41.000000
==> Total testing loss: 158.562863    Total testing error rate: 43.400000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 10
0.000000/1000.000000 ==> Training loss: 1.127269    Training error rate: 34.000000
50.000000/1000.000000 ==> Training loss: 0.914290    Training error rate: 30.000000
100.000000/1000.000000 ==> Training loss: 1.374206    Training error rate: 44.000000
150.000000/1000.000000 ==> Training loss: 1.269482    Training error rate: 34.000000
200.000000/1000.000000 ==> Training loss: 1.539564    Training error rate: 42.000000
250.000000/1000.000000 ==> Training loss: 1.160844    Training error rate: 32.000000
300.000000/1000.000000 ==> Training loss: 1.124813    Training error rate: 30.000000
350.000000/1000.000000 ==> Training loss: 1.109545    Training error rate: 32.000000
400.000000/1000.000000 ==> Training loss: 1.299565    Training error rate: 38.000000
450.000000/1000.000000 ==> Training loss: 0.999025    Training error rate: 24.000000
500.000000/1000.000000 ==> Training loss: 1.297856    Training error rate: 46.000000
550.000000/1000.000000 ==> Training loss: 1.354993    Training error rate: 44.000000
600.000000/1000.000000 ==> Training loss: 1.622232    Training error rate: 40.000000
650.000000/1000.000000 ==> Training loss: 0.986281    Training error rate: 32.000000
700.000000/1000.000000 ==> Training loss: 1.058213    Training error rate: 26.000000
750.000000/1000.000000 ==> Training loss: 1.307282    Training error rate: 40.000000
800.000000/1000.000000 ==> Training loss: 1.145484    Training error rate: 38.000000
850.000000/1000.000000 ==> Training loss: 1.321841    Training error rate: 34.000000
900.000000/1000.000000 ==> Training loss: 1.614299    Training error rate: 42.000000
950.000000/1000.000000 ==> Training loss: 1.086306    Training error rate: 38.000000
==> Total training loss: 1264.761092    Total training error rate: 36.776000
==> Testing Epoch: 10
0.000000/100.000000 ==> Testing loss: 1.520069    Testing error rate: 39.000000
50.000000/100.000000 ==> Testing loss: 1.569187    Testing error rate: 48.000000
==> Total testing loss: 153.383898    Total testing error rate: 42.820000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 11
0.000000/1000.000000 ==> Training loss: 1.277076    Training error rate: 32.000000
50.000000/1000.000000 ==> Training loss: 0.991139    Training error rate: 28.000000
100.000000/1000.000000 ==> Training loss: 1.066979    Training error rate: 34.000000
150.000000/1000.000000 ==> Training loss: 1.152336    Training error rate: 26.000000
200.000000/1000.000000 ==> Training loss: 1.175663    Training error rate: 32.000000
250.000000/1000.000000 ==> Training loss: 0.905477    Training error rate: 28.000000
300.000000/1000.000000 ==> Training loss: 1.144198    Training error rate: 36.000000
350.000000/1000.000000 ==> Training loss: 1.028686    Training error rate: 30.000000
400.000000/1000.000000 ==> Training loss: 0.925387    Training error rate: 22.000000
450.000000/1000.000000 ==> Training loss: 1.261633    Training error rate: 34.000000
500.000000/1000.000000 ==> Training loss: 1.079347    Training error rate: 32.000000
550.000000/1000.000000 ==> Training loss: 1.053172    Training error rate: 26.000000
600.000000/1000.000000 ==> Training loss: 1.252962    Training error rate: 40.000000
650.000000/1000.000000 ==> Training loss: 1.524243    Training error rate: 38.000000
700.000000/1000.000000 ==> Training loss: 0.965748    Training error rate: 30.000000
750.000000/1000.000000 ==> Training loss: 0.940129    Training error rate: 28.000000
800.000000/1000.000000 ==> Training loss: 1.282686    Training error rate: 36.000000
850.000000/1000.000000 ==> Training loss: 1.197121    Training error rate: 36.000000
900.000000/1000.000000 ==> Training loss: 1.090575    Training error rate: 36.000000
950.000000/1000.000000 ==> Training loss: 1.514838    Training error rate: 48.000000
==> Total training loss: 1192.464574    Total training error rate: 34.850000
==> Testing Epoch: 11
0.000000/100.000000 ==> Testing loss: 1.536982    Testing error rate: 39.000000
50.000000/100.000000 ==> Testing loss: 1.454350    Testing error rate: 40.000000
==> Total testing loss: 151.748784    Total testing error rate: 41.330000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 12
0.000000/1000.000000 ==> Training loss: 0.916340    Training error rate: 26.000000
50.000000/1000.000000 ==> Training loss: 1.035779    Training error rate: 32.000000
100.000000/1000.000000 ==> Training loss: 0.988614    Training error rate: 34.000000
150.000000/1000.000000 ==> Training loss: 0.966798    Training error rate: 36.000000
200.000000/1000.000000 ==> Training loss: 0.921960    Training error rate: 22.000000
250.000000/1000.000000 ==> Training loss: 0.966331    Training error rate: 28.000000
300.000000/1000.000000 ==> Training loss: 1.115003    Training error rate: 32.000000
350.000000/1000.000000 ==> Training loss: 1.480008    Training error rate: 34.000000
400.000000/1000.000000 ==> Training loss: 1.090021    Training error rate: 38.000000
450.000000/1000.000000 ==> Training loss: 1.344108    Training error rate: 28.000000
500.000000/1000.000000 ==> Training loss: 1.609426    Training error rate: 44.000000
550.000000/1000.000000 ==> Training loss: 1.519184    Training error rate: 40.000000
600.000000/1000.000000 ==> Training loss: 1.015069    Training error rate: 26.000000
650.000000/1000.000000 ==> Training loss: 1.231734    Training error rate: 42.000000
700.000000/1000.000000 ==> Training loss: 1.223767    Training error rate: 38.000000
750.000000/1000.000000 ==> Training loss: 1.130753    Training error rate: 36.000000
800.000000/1000.000000 ==> Training loss: 1.391288    Training error rate: 46.000000
850.000000/1000.000000 ==> Training loss: 1.672158    Training error rate: 48.000000
900.000000/1000.000000 ==> Training loss: 1.168818    Training error rate: 44.000000
950.000000/1000.000000 ==> Training loss: 1.239542    Training error rate: 30.000000
==> Total training loss: 1137.483644    Total training error rate: 33.604000
==> Testing Epoch: 12
0.000000/100.000000 ==> Testing loss: 1.339770    Testing error rate: 38.000000
50.000000/100.000000 ==> Testing loss: 1.265780    Testing error rate: 37.000000
==> Total testing loss: 137.313995    Total testing error rate: 38.380000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 13
0.000000/1000.000000 ==> Training loss: 1.058642    Training error rate: 32.000000
50.000000/1000.000000 ==> Training loss: 1.032299    Training error rate: 30.000000
100.000000/1000.000000 ==> Training loss: 1.086450    Training error rate: 34.000000
150.000000/1000.000000 ==> Training loss: 1.002234    Training error rate: 36.000000
200.000000/1000.000000 ==> Training loss: 0.994289    Training error rate: 28.000000
250.000000/1000.000000 ==> Training loss: 0.637248    Training error rate: 16.000000
300.000000/1000.000000 ==> Training loss: 1.058021    Training error rate: 30.000000
350.000000/1000.000000 ==> Training loss: 1.040632    Training error rate: 34.000000
400.000000/1000.000000 ==> Training loss: 1.363738    Training error rate: 36.000000
450.000000/1000.000000 ==> Training loss: 1.142041    Training error rate: 28.000000
500.000000/1000.000000 ==> Training loss: 1.200426    Training error rate: 36.000000
550.000000/1000.000000 ==> Training loss: 0.908906    Training error rate: 28.000000
600.000000/1000.000000 ==> Training loss: 1.054829    Training error rate: 28.000000
650.000000/1000.000000 ==> Training loss: 1.124004    Training error rate: 32.000000
700.000000/1000.000000 ==> Training loss: 1.240938    Training error rate: 38.000000
750.000000/1000.000000 ==> Training loss: 0.923893    Training error rate: 22.000000
800.000000/1000.000000 ==> Training loss: 1.156032    Training error rate: 36.000000
850.000000/1000.000000 ==> Training loss: 1.279199    Training error rate: 36.000000
900.000000/1000.000000 ==> Training loss: 1.127662    Training error rate: 32.000000
950.000000/1000.000000 ==> Training loss: 0.872122    Training error rate: 26.000000
==> Total training loss: 1065.626828    Total training error rate: 31.578000
==> Testing Epoch: 13
0.000000/100.000000 ==> Testing loss: 1.414016    Testing error rate: 37.000000
50.000000/100.000000 ==> Testing loss: 1.301788    Testing error rate: 37.000000
==> Total testing loss: 140.237611    Total testing error rate: 38.560000
==> Set learning rate: 0.010000
==> Training Epoch: 14
0.000000/1000.000000 ==> Training loss: 1.167549    Training error rate: 30.000000
50.000000/1000.000000 ==> Training loss: 0.615478    Training error rate: 16.000000
100.000000/1000.000000 ==> Training loss: 1.298394    Training error rate: 38.000000
150.000000/1000.000000 ==> Training loss: 1.413032    Training error rate: 42.000000
200.000000/1000.000000 ==> Training loss: 0.930385    Training error rate: 28.000000
250.000000/1000.000000 ==> Training loss: 0.857595    Training error rate: 22.000000
300.000000/1000.000000 ==> Training loss: 1.174563    Training error rate: 34.000000
350.000000/1000.000000 ==> Training loss: 0.921344    Training error rate: 26.000000
400.000000/1000.000000 ==> Training loss: 1.339101    Training error rate: 34.000000
450.000000/1000.000000 ==> Training loss: 0.928363    Training error rate: 28.000000
500.000000/1000.000000 ==> Training loss: 1.051335    Training error rate: 32.000000
550.000000/1000.000000 ==> Training loss: 1.057788    Training error rate: 30.000000
600.000000/1000.000000 ==> Training loss: 1.393381    Training error rate: 40.000000
650.000000/1000.000000 ==> Training loss: 0.784437    Training error rate: 32.000000
700.000000/1000.000000 ==> Training loss: 0.984048    Training error rate: 30.000000
750.000000/1000.000000 ==> Training loss: 0.830300    Training error rate: 22.000000
800.000000/1000.000000 ==> Training loss: 1.143346    Training error rate: 34.000000
850.000000/1000.000000 ==> Training loss: 1.114062    Training error rate: 32.000000
900.000000/1000.000000 ==> Training loss: 1.186273    Training error rate: 34.000000
950.000000/1000.000000 ==> Training loss: 0.812064    Training error rate: 30.000000
==> Total training loss: 1014.532494    Total training error rate: 30.392000
==> Testing Epoch: 14
0.000000/100.000000 ==> Testing loss: 1.321891    Testing error rate: 38.000000
50.000000/100.000000 ==> Testing loss: 1.277451    Testing error rate: 39.000000
==> Total testing loss: 138.104633    Total testing error rate: 38.160000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 15
0.000000/1000.000000 ==> Training loss: 1.082424    Training error rate: 32.000000
50.000000/1000.000000 ==> Training loss: 0.718677    Training error rate: 14.000000
100.000000/1000.000000 ==> Training loss: 1.110957    Training error rate: 32.000000
150.000000/1000.000000 ==> Training loss: 0.922839    Training error rate: 36.000000
200.000000/1000.000000 ==> Training loss: 0.930745    Training error rate: 28.000000
250.000000/1000.000000 ==> Training loss: 0.806325    Training error rate: 24.000000
300.000000/1000.000000 ==> Training loss: 0.908623    Training error rate: 28.000000
350.000000/1000.000000 ==> Training loss: 0.739204    Training error rate: 20.000000
400.000000/1000.000000 ==> Training loss: 0.711550    Training error rate: 18.000000
450.000000/1000.000000 ==> Training loss: 0.866226    Training error rate: 26.000000
500.000000/1000.000000 ==> Training loss: 1.224664    Training error rate: 36.000000
550.000000/1000.000000 ==> Training loss: 0.779607    Training error rate: 26.000000
600.000000/1000.000000 ==> Training loss: 0.769280    Training error rate: 24.000000
650.000000/1000.000000 ==> Training loss: 0.577752    Training error rate: 16.000000
700.000000/1000.000000 ==> Training loss: 0.848075    Training error rate: 24.000000
750.000000/1000.000000 ==> Training loss: 0.925577    Training error rate: 22.000000
800.000000/1000.000000 ==> Training loss: 1.265697    Training error rate: 40.000000
850.000000/1000.000000 ==> Training loss: 0.840295    Training error rate: 32.000000
900.000000/1000.000000 ==> Training loss: 1.017447    Training error rate: 34.000000
950.000000/1000.000000 ==> Training loss: 1.073649    Training error rate: 30.000000
==> Total training loss: 970.769671    Total training error rate: 28.936000
==> Testing Epoch: 15
0.000000/100.000000 ==> Testing loss: 1.491467    Testing error rate: 35.000000
50.000000/100.000000 ==> Testing loss: 1.274029    Testing error rate: 38.000000
==> Total testing loss: 141.404832    Total testing error rate: 38.560000
==> Set learning rate: 0.010000
==> Training Epoch: 16
0.000000/1000.000000 ==> Training loss: 0.773890    Training error rate: 26.000000
50.000000/1000.000000 ==> Training loss: 0.797003    Training error rate: 12.000000
100.000000/1000.000000 ==> Training loss: 0.786365    Training error rate: 30.000000
150.000000/1000.000000 ==> Training loss: 1.023060    Training error rate: 32.000000
200.000000/1000.000000 ==> Training loss: 0.792468    Training error rate: 24.000000
250.000000/1000.000000 ==> Training loss: 0.852215    Training error rate: 24.000000
300.000000/1000.000000 ==> Training loss: 1.073390    Training error rate: 36.000000
350.000000/1000.000000 ==> Training loss: 0.852974    Training error rate: 24.000000
400.000000/1000.000000 ==> Training loss: 0.589342    Training error rate: 18.000000
450.000000/1000.000000 ==> Training loss: 1.084637    Training error rate: 34.000000
500.000000/1000.000000 ==> Training loss: 0.912943    Training error rate: 22.000000
550.000000/1000.000000 ==> Training loss: 1.189799    Training error rate: 32.000000
600.000000/1000.000000 ==> Training loss: 0.599488    Training error rate: 22.000000
650.000000/1000.000000 ==> Training loss: 0.937433    Training error rate: 22.000000
700.000000/1000.000000 ==> Training loss: 1.297812    Training error rate: 38.000000
750.000000/1000.000000 ==> Training loss: 0.871599    Training error rate: 22.000000
800.000000/1000.000000 ==> Training loss: 0.849970    Training error rate: 26.000000
850.000000/1000.000000 ==> Training loss: 1.132597    Training error rate: 32.000000
900.000000/1000.000000 ==> Training loss: 0.572704    Training error rate: 18.000000
950.000000/1000.000000 ==> Training loss: 1.154377    Training error rate: 34.000000
==> Total training loss: 926.275672    Total training error rate: 27.574000
==> Testing Epoch: 16
0.000000/100.000000 ==> Testing loss: 1.552259    Testing error rate: 39.000000
50.000000/100.000000 ==> Testing loss: 1.352296    Testing error rate: 36.000000
==> Total testing loss: 140.191303    Total testing error rate: 37.490000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 17
0.000000/1000.000000 ==> Training loss: 0.989987    Training error rate: 32.000000
50.000000/1000.000000 ==> Training loss: 0.861140    Training error rate: 22.000000
100.000000/1000.000000 ==> Training loss: 0.685140    Training error rate: 20.000000
150.000000/1000.000000 ==> Training loss: 0.777974    Training error rate: 18.000000
200.000000/1000.000000 ==> Training loss: 0.729270    Training error rate: 16.000000
250.000000/1000.000000 ==> Training loss: 0.923990    Training error rate: 32.000000
300.000000/1000.000000 ==> Training loss: 0.969927    Training error rate: 34.000000
350.000000/1000.000000 ==> Training loss: 0.963170    Training error rate: 32.000000
400.000000/1000.000000 ==> Training loss: 0.787623    Training error rate: 26.000000
450.000000/1000.000000 ==> Training loss: 0.846136    Training error rate: 24.000000
500.000000/1000.000000 ==> Training loss: 0.618683    Training error rate: 24.000000
550.000000/1000.000000 ==> Training loss: 0.635383    Training error rate: 20.000000
600.000000/1000.000000 ==> Training loss: 0.778103    Training error rate: 22.000000
650.000000/1000.000000 ==> Training loss: 0.738652    Training error rate: 30.000000
700.000000/1000.000000 ==> Training loss: 0.993186    Training error rate: 30.000000
750.000000/1000.000000 ==> Training loss: 1.182221    Training error rate: 32.000000
800.000000/1000.000000 ==> Training loss: 0.973516    Training error rate: 28.000000
850.000000/1000.000000 ==> Training loss: 1.175011    Training error rate: 42.000000
900.000000/1000.000000 ==> Training loss: 0.548379    Training error rate: 10.000000
950.000000/1000.000000 ==> Training loss: 1.161326    Training error rate: 42.000000
==> Total training loss: 876.895463    Total training error rate: 26.412000
==> Testing Epoch: 17
0.000000/100.000000 ==> Testing loss: 1.392524    Testing error rate: 38.000000
50.000000/100.000000 ==> Testing loss: 1.313979    Testing error rate: 35.000000
==> Total testing loss: 136.357470    Total testing error rate: 37.340000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 18
0.000000/1000.000000 ==> Training loss: 0.747835    Training error rate: 22.000000
50.000000/1000.000000 ==> Training loss: 0.965643    Training error rate: 24.000000
100.000000/1000.000000 ==> Training loss: 0.993238    Training error rate: 28.000000
150.000000/1000.000000 ==> Training loss: 0.730728    Training error rate: 28.000000
200.000000/1000.000000 ==> Training loss: 0.835863    Training error rate: 24.000000
250.000000/1000.000000 ==> Training loss: 0.699550    Training error rate: 26.000000
300.000000/1000.000000 ==> Training loss: 0.871759    Training error rate: 34.000000
350.000000/1000.000000 ==> Training loss: 0.990221    Training error rate: 32.000000
400.000000/1000.000000 ==> Training loss: 0.655672    Training error rate: 26.000000
450.000000/1000.000000 ==> Training loss: 0.958677    Training error rate: 18.000000
500.000000/1000.000000 ==> Training loss: 0.966372    Training error rate: 30.000000
550.000000/1000.000000 ==> Training loss: 1.028988    Training error rate: 30.000000
600.000000/1000.000000 ==> Training loss: 0.853863    Training error rate: 30.000000
650.000000/1000.000000 ==> Training loss: 0.846106    Training error rate: 32.000000
700.000000/1000.000000 ==> Training loss: 0.704118    Training error rate: 22.000000
750.000000/1000.000000 ==> Training loss: 1.181533    Training error rate: 30.000000
800.000000/1000.000000 ==> Training loss: 0.718850    Training error rate: 16.000000
850.000000/1000.000000 ==> Training loss: 0.873501    Training error rate: 22.000000
900.000000/1000.000000 ==> Training loss: 0.789546    Training error rate: 34.000000
950.000000/1000.000000 ==> Training loss: 0.690937    Training error rate: 20.000000
==> Total training loss: 839.478256    Total training error rate: 25.366000
==> Testing Epoch: 18
0.000000/100.000000 ==> Testing loss: 1.486598    Testing error rate: 32.000000
50.000000/100.000000 ==> Testing loss: 1.362306    Testing error rate: 38.000000
==> Total testing loss: 140.769592    Total testing error rate: 37.470000
==> Set learning rate: 0.010000
==> Training Epoch: 19
0.000000/1000.000000 ==> Training loss: 0.844478    Training error rate: 24.000000
50.000000/1000.000000 ==> Training loss: 0.785652    Training error rate: 32.000000
100.000000/1000.000000 ==> Training loss: 0.806642    Training error rate: 20.000000
150.000000/1000.000000 ==> Training loss: 0.829682    Training error rate: 26.000000
200.000000/1000.000000 ==> Training loss: 0.589941    Training error rate: 24.000000
250.000000/1000.000000 ==> Training loss: 0.905157    Training error rate: 22.000000
300.000000/1000.000000 ==> Training loss: 0.859007    Training error rate: 28.000000
350.000000/1000.000000 ==> Training loss: 0.805072    Training error rate: 26.000000
400.000000/1000.000000 ==> Training loss: 0.882141    Training error rate: 28.000000
450.000000/1000.000000 ==> Training loss: 0.867728    Training error rate: 24.000000
500.000000/1000.000000 ==> Training loss: 0.739874    Training error rate: 18.000000
550.000000/1000.000000 ==> Training loss: 0.980602    Training error rate: 24.000000
600.000000/1000.000000 ==> Training loss: 0.771543    Training error rate: 24.000000
650.000000/1000.000000 ==> Training loss: 1.027802    Training error rate: 36.000000
700.000000/1000.000000 ==> Training loss: 1.039709    Training error rate: 26.000000
750.000000/1000.000000 ==> Training loss: 0.764902    Training error rate: 24.000000
800.000000/1000.000000 ==> Training loss: 1.004686    Training error rate: 34.000000
850.000000/1000.000000 ==> Training loss: 0.766458    Training error rate: 24.000000
900.000000/1000.000000 ==> Training loss: 0.900019    Training error rate: 26.000000
950.000000/1000.000000 ==> Training loss: 1.072572    Training error rate: 28.000000
==> Total training loss: 815.538138    Total training error rate: 24.734000
==> Testing Epoch: 19
0.000000/100.000000 ==> Testing loss: 1.374724    Testing error rate: 37.000000
50.000000/100.000000 ==> Testing loss: 1.176405    Testing error rate: 40.000000
==> Total testing loss: 126.737332    Total testing error rate: 34.570000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 20
0.000000/1000.000000 ==> Training loss: 0.785515    Training error rate: 26.000000
50.000000/1000.000000 ==> Training loss: 0.532509    Training error rate: 18.000000
100.000000/1000.000000 ==> Training loss: 0.566648    Training error rate: 18.000000
150.000000/1000.000000 ==> Training loss: 0.640309    Training error rate: 18.000000
200.000000/1000.000000 ==> Training loss: 0.911580    Training error rate: 22.000000
250.000000/1000.000000 ==> Training loss: 0.751673    Training error rate: 24.000000
300.000000/1000.000000 ==> Training loss: 0.624931    Training error rate: 16.000000
350.000000/1000.000000 ==> Training loss: 0.907781    Training error rate: 22.000000
400.000000/1000.000000 ==> Training loss: 0.786080    Training error rate: 28.000000
450.000000/1000.000000 ==> Training loss: 0.757331    Training error rate: 24.000000
500.000000/1000.000000 ==> Training loss: 0.612945    Training error rate: 16.000000
550.000000/1000.000000 ==> Training loss: 0.977622    Training error rate: 34.000000
600.000000/1000.000000 ==> Training loss: 0.555528    Training error rate: 18.000000
650.000000/1000.000000 ==> Training loss: 0.930917    Training error rate: 26.000000
700.000000/1000.000000 ==> Training loss: 0.803683    Training error rate: 18.000000
750.000000/1000.000000 ==> Training loss: 0.780337    Training error rate: 22.000000
800.000000/1000.000000 ==> Training loss: 0.748133    Training error rate: 26.000000
850.000000/1000.000000 ==> Training loss: 0.848198    Training error rate: 28.000000
900.000000/1000.000000 ==> Training loss: 1.119685    Training error rate: 34.000000
950.000000/1000.000000 ==> Training loss: 0.917857    Training error rate: 22.000000
==> Total training loss: 778.939379    Total training error rate: 23.738000
==> Testing Epoch: 20
0.000000/100.000000 ==> Testing loss: 1.509945    Testing error rate: 38.000000
50.000000/100.000000 ==> Testing loss: 1.266751    Testing error rate: 32.000000
==> Total testing loss: 135.642338    Total testing error rate: 35.720000
==> Set learning rate: 0.010000
==> Training Epoch: 21
0.000000/1000.000000 ==> Training loss: 0.788445    Training error rate: 30.000000
50.000000/1000.000000 ==> Training loss: 0.606341    Training error rate: 14.000000
100.000000/1000.000000 ==> Training loss: 0.590396    Training error rate: 24.000000
150.000000/1000.000000 ==> Training loss: 1.099056    Training error rate: 28.000000
200.000000/1000.000000 ==> Training loss: 0.493431    Training error rate: 10.000000
250.000000/1000.000000 ==> Training loss: 0.592186    Training error rate: 16.000000
300.000000/1000.000000 ==> Training loss: 0.866831    Training error rate: 28.000000
350.000000/1000.000000 ==> Training loss: 0.617405    Training error rate: 14.000000
400.000000/1000.000000 ==> Training loss: 0.680964    Training error rate: 26.000000
450.000000/1000.000000 ==> Training loss: 0.860459    Training error rate: 30.000000
500.000000/1000.000000 ==> Training loss: 0.631994    Training error rate: 16.000000
550.000000/1000.000000 ==> Training loss: 1.031989    Training error rate: 26.000000
600.000000/1000.000000 ==> Training loss: 0.836860    Training error rate: 26.000000
650.000000/1000.000000 ==> Training loss: 0.588906    Training error rate: 24.000000
700.000000/1000.000000 ==> Training loss: 0.669800    Training error rate: 20.000000
750.000000/1000.000000 ==> Training loss: 0.844803    Training error rate: 28.000000
800.000000/1000.000000 ==> Training loss: 0.589941    Training error rate: 18.000000
850.000000/1000.000000 ==> Training loss: 0.648978    Training error rate: 22.000000
900.000000/1000.000000 ==> Training loss: 1.070137    Training error rate: 34.000000
950.000000/1000.000000 ==> Training loss: 0.895195    Training error rate: 32.000000
==> Total training loss: 746.213079    Total training error rate: 22.844000
==> Testing Epoch: 21
0.000000/100.000000 ==> Testing loss: 1.564177    Testing error rate: 32.000000
50.000000/100.000000 ==> Testing loss: 1.404623    Testing error rate: 37.000000
==> Total testing loss: 125.738151    Total testing error rate: 33.840000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 22
0.000000/1000.000000 ==> Training loss: 0.666921    Training error rate: 26.000000
50.000000/1000.000000 ==> Training loss: 0.642451    Training error rate: 16.000000
100.000000/1000.000000 ==> Training loss: 0.562057    Training error rate: 16.000000
150.000000/1000.000000 ==> Training loss: 0.750967    Training error rate: 24.000000
200.000000/1000.000000 ==> Training loss: 1.093671    Training error rate: 32.000000
250.000000/1000.000000 ==> Training loss: 0.569178    Training error rate: 14.000000
300.000000/1000.000000 ==> Training loss: 0.695258    Training error rate: 24.000000
350.000000/1000.000000 ==> Training loss: 0.587666    Training error rate: 24.000000
400.000000/1000.000000 ==> Training loss: 0.765953    Training error rate: 32.000000
450.000000/1000.000000 ==> Training loss: 0.811486    Training error rate: 26.000000
500.000000/1000.000000 ==> Training loss: 0.514768    Training error rate: 10.000000
550.000000/1000.000000 ==> Training loss: 0.792436    Training error rate: 16.000000
600.000000/1000.000000 ==> Training loss: 0.841483    Training error rate: 28.000000
650.000000/1000.000000 ==> Training loss: 0.940355    Training error rate: 32.000000
700.000000/1000.000000 ==> Training loss: 0.566132    Training error rate: 18.000000
750.000000/1000.000000 ==> Training loss: 0.567900    Training error rate: 12.000000
800.000000/1000.000000 ==> Training loss: 0.492992    Training error rate: 16.000000
850.000000/1000.000000 ==> Training loss: 0.486582    Training error rate: 12.000000
900.000000/1000.000000 ==> Training loss: 1.061438    Training error rate: 32.000000
950.000000/1000.000000 ==> Training loss: 0.622288    Training error rate: 20.000000
==> Total training loss: 723.447096    Total training error rate: 22.204000
==> Testing Epoch: 22
0.000000/100.000000 ==> Testing loss: 1.392507    Testing error rate: 36.000000
50.000000/100.000000 ==> Testing loss: 1.301084    Testing error rate: 34.000000
==> Total testing loss: 130.540428    Total testing error rate: 34.830000
==> Set learning rate: 0.010000
==> Training Epoch: 23
0.000000/1000.000000 ==> Training loss: 0.638311    Training error rate: 20.000000
50.000000/1000.000000 ==> Training loss: 0.465278    Training error rate: 16.000000
100.000000/1000.000000 ==> Training loss: 0.776515    Training error rate: 24.000000
150.000000/1000.000000 ==> Training loss: 0.510650    Training error rate: 16.000000
200.000000/1000.000000 ==> Training loss: 0.543486    Training error rate: 18.000000
250.000000/1000.000000 ==> Training loss: 0.833270    Training error rate: 30.000000
300.000000/1000.000000 ==> Training loss: 0.830402    Training error rate: 32.000000
350.000000/1000.000000 ==> Training loss: 0.621556    Training error rate: 24.000000
400.000000/1000.000000 ==> Training loss: 0.898599    Training error rate: 26.000000
450.000000/1000.000000 ==> Training loss: 0.819961    Training error rate: 26.000000
500.000000/1000.000000 ==> Training loss: 0.515224    Training error rate: 14.000000
550.000000/1000.000000 ==> Training loss: 0.653748    Training error rate: 20.000000
600.000000/1000.000000 ==> Training loss: 1.024992    Training error rate: 30.000000
650.000000/1000.000000 ==> Training loss: 0.549328    Training error rate: 14.000000
700.000000/1000.000000 ==> Training loss: 0.530326    Training error rate: 10.000000
750.000000/1000.000000 ==> Training loss: 0.719696    Training error rate: 18.000000
800.000000/1000.000000 ==> Training loss: 1.014239    Training error rate: 32.000000
850.000000/1000.000000 ==> Training loss: 0.575091    Training error rate: 20.000000
900.000000/1000.000000 ==> Training loss: 0.447621    Training error rate: 10.000000
950.000000/1000.000000 ==> Training loss: 0.813376    Training error rate: 24.000000
==> Total training loss: 702.869792    Total training error rate: 21.438000
==> Testing Epoch: 23
0.000000/100.000000 ==> Testing loss: 1.258484    Testing error rate: 31.000000
50.000000/100.000000 ==> Testing loss: 1.411851    Testing error rate: 36.000000
==> Total testing loss: 131.639998    Total testing error rate: 34.830000
==> Set learning rate: 0.010000
==> Training Epoch: 24
0.000000/1000.000000 ==> Training loss: 0.575412    Training error rate: 14.000000
50.000000/1000.000000 ==> Training loss: 0.521479    Training error rate: 14.000000
100.000000/1000.000000 ==> Training loss: 0.678983    Training error rate: 18.000000
150.000000/1000.000000 ==> Training loss: 0.443301    Training error rate: 10.000000
200.000000/1000.000000 ==> Training loss: 0.731521    Training error rate: 22.000000
250.000000/1000.000000 ==> Training loss: 0.487508    Training error rate: 16.000000
300.000000/1000.000000 ==> Training loss: 0.607733    Training error rate: 18.000000
350.000000/1000.000000 ==> Training loss: 0.707745    Training error rate: 22.000000
400.000000/1000.000000 ==> Training loss: 0.667512    Training error rate: 22.000000
450.000000/1000.000000 ==> Training loss: 0.732874    Training error rate: 16.000000
500.000000/1000.000000 ==> Training loss: 0.838755    Training error rate: 28.000000
550.000000/1000.000000 ==> Training loss: 0.789750    Training error rate: 28.000000
600.000000/1000.000000 ==> Training loss: 0.694835    Training error rate: 20.000000
650.000000/1000.000000 ==> Training loss: 0.575121    Training error rate: 16.000000
700.000000/1000.000000 ==> Training loss: 0.912670    Training error rate: 22.000000
750.000000/1000.000000 ==> Training loss: 0.735826    Training error rate: 22.000000
800.000000/1000.000000 ==> Training loss: 0.740454    Training error rate: 28.000000
850.000000/1000.000000 ==> Training loss: 0.740071    Training error rate: 24.000000
900.000000/1000.000000 ==> Training loss: 0.769146    Training error rate: 28.000000
950.000000/1000.000000 ==> Training loss: 0.483384    Training error rate: 16.000000
==> Total training loss: 670.226951    Total training error rate: 20.668000
==> Testing Epoch: 24
0.000000/100.000000 ==> Testing loss: 1.386963    Testing error rate: 32.000000
50.000000/100.000000 ==> Testing loss: 1.528685    Testing error rate: 37.000000
==> Total testing loss: 132.093839    Total testing error rate: 35.250000
==> Set learning rate: 0.010000
==> Training Epoch: 25
0.000000/1000.000000 ==> Training loss: 0.695578    Training error rate: 22.000000
50.000000/1000.000000 ==> Training loss: 0.808278    Training error rate: 22.000000
100.000000/1000.000000 ==> Training loss: 0.313482    Training error rate: 10.000000
150.000000/1000.000000 ==> Training loss: 0.486367    Training error rate: 14.000000
200.000000/1000.000000 ==> Training loss: 0.891501    Training error rate: 32.000000
250.000000/1000.000000 ==> Training loss: 0.713463    Training error rate: 26.000000
300.000000/1000.000000 ==> Training loss: 0.538335    Training error rate: 26.000000
350.000000/1000.000000 ==> Training loss: 0.964033    Training error rate: 32.000000
400.000000/1000.000000 ==> Training loss: 1.033171    Training error rate: 32.000000
450.000000/1000.000000 ==> Training loss: 0.813932    Training error rate: 28.000000
500.000000/1000.000000 ==> Training loss: 0.848987    Training error rate: 26.000000
550.000000/1000.000000 ==> Training loss: 0.804521    Training error rate: 28.000000
600.000000/1000.000000 ==> Training loss: 0.613668    Training error rate: 24.000000
650.000000/1000.000000 ==> Training loss: 0.437862    Training error rate: 12.000000
700.000000/1000.000000 ==> Training loss: 0.561901    Training error rate: 22.000000
750.000000/1000.000000 ==> Training loss: 0.700412    Training error rate: 24.000000
800.000000/1000.000000 ==> Training loss: 0.661576    Training error rate: 14.000000
850.000000/1000.000000 ==> Training loss: 1.166256    Training error rate: 28.000000
900.000000/1000.000000 ==> Training loss: 0.428528    Training error rate: 14.000000
950.000000/1000.000000 ==> Training loss: 0.586165    Training error rate: 20.000000
==> Total training loss: 656.643817    Total training error rate: 20.378000
==> Testing Epoch: 25
0.000000/100.000000 ==> Testing loss: 1.105060    Testing error rate: 30.000000
50.000000/100.000000 ==> Testing loss: 1.351349    Testing error rate: 32.000000
==> Total testing loss: 126.121821    Total testing error rate: 34.310000
==> Set learning rate: 0.010000
==> Training Epoch: 26
0.000000/1000.000000 ==> Training loss: 0.542189    Training error rate: 18.000000
50.000000/1000.000000 ==> Training loss: 0.599944    Training error rate: 24.000000
100.000000/1000.000000 ==> Training loss: 0.832419    Training error rate: 24.000000
150.000000/1000.000000 ==> Training loss: 0.392000    Training error rate: 12.000000
200.000000/1000.000000 ==> Training loss: 0.524695    Training error rate: 20.000000
250.000000/1000.000000 ==> Training loss: 0.714452    Training error rate: 28.000000
300.000000/1000.000000 ==> Training loss: 0.734329    Training error rate: 20.000000
350.000000/1000.000000 ==> Training loss: 0.932302    Training error rate: 30.000000
400.000000/1000.000000 ==> Training loss: 0.492087    Training error rate: 10.000000
450.000000/1000.000000 ==> Training loss: 0.651308    Training error rate: 26.000000
500.000000/1000.000000 ==> Training loss: 0.714161    Training error rate: 18.000000
550.000000/1000.000000 ==> Training loss: 0.488817    Training error rate: 12.000000
600.000000/1000.000000 ==> Training loss: 0.531895    Training error rate: 12.000000
650.000000/1000.000000 ==> Training loss: 0.905741    Training error rate: 22.000000
700.000000/1000.000000 ==> Training loss: 0.768607    Training error rate: 24.000000
750.000000/1000.000000 ==> Training loss: 0.712992    Training error rate: 26.000000
800.000000/1000.000000 ==> Training loss: 1.000236    Training error rate: 30.000000
850.000000/1000.000000 ==> Training loss: 0.783921    Training error rate: 26.000000
900.000000/1000.000000 ==> Training loss: 0.676696    Training error rate: 20.000000
950.000000/1000.000000 ==> Training loss: 0.849224    Training error rate: 22.000000
==> Total training loss: 645.349909    Total training error rate: 19.934000
==> Testing Epoch: 26
0.000000/100.000000 ==> Testing loss: 1.379303    Testing error rate: 37.000000
50.000000/100.000000 ==> Testing loss: 1.330309    Testing error rate: 37.000000
==> Total testing loss: 135.691417    Total testing error rate: 35.890000
==> Set learning rate: 0.010000
==> Training Epoch: 27
0.000000/1000.000000 ==> Training loss: 0.599483    Training error rate: 20.000000
50.000000/1000.000000 ==> Training loss: 0.575068    Training error rate: 14.000000
100.000000/1000.000000 ==> Training loss: 0.882844    Training error rate: 22.000000
150.000000/1000.000000 ==> Training loss: 0.586401    Training error rate: 16.000000
200.000000/1000.000000 ==> Training loss: 0.690087    Training error rate: 18.000000
250.000000/1000.000000 ==> Training loss: 0.495231    Training error rate: 14.000000
300.000000/1000.000000 ==> Training loss: 0.503056    Training error rate: 16.000000
350.000000/1000.000000 ==> Training loss: 0.488777    Training error rate: 8.000000
400.000000/1000.000000 ==> Training loss: 0.421806    Training error rate: 12.000000
450.000000/1000.000000 ==> Training loss: 0.447002    Training error rate: 12.000000
500.000000/1000.000000 ==> Training loss: 0.574232    Training error rate: 16.000000
550.000000/1000.000000 ==> Training loss: 0.781922    Training error rate: 24.000000
600.000000/1000.000000 ==> Training loss: 0.761938    Training error rate: 26.000000
650.000000/1000.000000 ==> Training loss: 0.643410    Training error rate: 20.000000
700.000000/1000.000000 ==> Training loss: 0.530943    Training error rate: 20.000000
750.000000/1000.000000 ==> Training loss: 1.067413    Training error rate: 28.000000
800.000000/1000.000000 ==> Training loss: 0.831615    Training error rate: 24.000000
850.000000/1000.000000 ==> Training loss: 0.766037    Training error rate: 20.000000
900.000000/1000.000000 ==> Training loss: 0.606138    Training error rate: 22.000000
950.000000/1000.000000 ==> Training loss: 0.715205    Training error rate: 18.000000
==> Total training loss: 624.030605    Total training error rate: 19.286000
==> Testing Epoch: 27
0.000000/100.000000 ==> Testing loss: 1.306090    Testing error rate: 32.000000
50.000000/100.000000 ==> Testing loss: 1.153219    Testing error rate: 34.000000
==> Total testing loss: 129.846768    Total testing error rate: 34.310000
==> Set learning rate: 0.010000
==> Training Epoch: 28
0.000000/1000.000000 ==> Training loss: 0.424738    Training error rate: 10.000000
50.000000/1000.000000 ==> Training loss: 0.476372    Training error rate: 18.000000
100.000000/1000.000000 ==> Training loss: 0.308943    Training error rate: 10.000000
150.000000/1000.000000 ==> Training loss: 0.660179    Training error rate: 20.000000
200.000000/1000.000000 ==> Training loss: 0.388784    Training error rate: 14.000000
250.000000/1000.000000 ==> Training loss: 0.508862    Training error rate: 16.000000
300.000000/1000.000000 ==> Training loss: 0.694797    Training error rate: 22.000000
350.000000/1000.000000 ==> Training loss: 0.767260    Training error rate: 22.000000
400.000000/1000.000000 ==> Training loss: 0.480577    Training error rate: 14.000000
450.000000/1000.000000 ==> Training loss: 0.629761    Training error rate: 20.000000
500.000000/1000.000000 ==> Training loss: 1.007729    Training error rate: 34.000000
550.000000/1000.000000 ==> Training loss: 0.700166    Training error rate: 20.000000
600.000000/1000.000000 ==> Training loss: 0.860205    Training error rate: 16.000000
650.000000/1000.000000 ==> Training loss: 0.340415    Training error rate: 8.000000
700.000000/1000.000000 ==> Training loss: 0.550272    Training error rate: 14.000000
750.000000/1000.000000 ==> Training loss: 0.813607    Training error rate: 28.000000
800.000000/1000.000000 ==> Training loss: 0.448084    Training error rate: 12.000000
850.000000/1000.000000 ==> Training loss: 0.940110    Training error rate: 34.000000
900.000000/1000.000000 ==> Training loss: 0.769187    Training error rate: 30.000000
950.000000/1000.000000 ==> Training loss: 0.431848    Training error rate: 14.000000
==> Total training loss: 604.320653    Total training error rate: 18.760000
==> Testing Epoch: 28
0.000000/100.000000 ==> Testing loss: 1.241890    Testing error rate: 33.000000
50.000000/100.000000 ==> Testing loss: 1.346455    Testing error rate: 36.000000
==> Total testing loss: 124.273606    Total testing error rate: 32.870000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 29
0.000000/1000.000000 ==> Training loss: 0.662134    Training error rate: 18.000000
50.000000/1000.000000 ==> Training loss: 0.550010    Training error rate: 20.000000
100.000000/1000.000000 ==> Training loss: 0.750713    Training error rate: 20.000000
150.000000/1000.000000 ==> Training loss: 0.476940    Training error rate: 16.000000
200.000000/1000.000000 ==> Training loss: 0.489109    Training error rate: 12.000000
250.000000/1000.000000 ==> Training loss: 0.350706    Training error rate: 14.000000
300.000000/1000.000000 ==> Training loss: 0.514942    Training error rate: 18.000000
350.000000/1000.000000 ==> Training loss: 0.332650    Training error rate: 12.000000
400.000000/1000.000000 ==> Training loss: 0.592370    Training error rate: 16.000000
450.000000/1000.000000 ==> Training loss: 0.618480    Training error rate: 22.000000
500.000000/1000.000000 ==> Training loss: 0.654236    Training error rate: 20.000000
550.000000/1000.000000 ==> Training loss: 0.623493    Training error rate: 22.000000
600.000000/1000.000000 ==> Training loss: 0.801973    Training error rate: 22.000000
650.000000/1000.000000 ==> Training loss: 0.513076    Training error rate: 16.000000
700.000000/1000.000000 ==> Training loss: 0.678834    Training error rate: 18.000000
750.000000/1000.000000 ==> Training loss: 0.737298    Training error rate: 16.000000
800.000000/1000.000000 ==> Training loss: 0.667650    Training error rate: 16.000000
850.000000/1000.000000 ==> Training loss: 0.549988    Training error rate: 24.000000
900.000000/1000.000000 ==> Training loss: 0.548265    Training error rate: 20.000000
950.000000/1000.000000 ==> Training loss: 0.441302    Training error rate: 14.000000
==> Total training loss: 583.158334    Total training error rate: 18.196000
==> Testing Epoch: 29
0.000000/100.000000 ==> Testing loss: 1.338244    Testing error rate: 35.000000
50.000000/100.000000 ==> Testing loss: 1.500650    Testing error rate: 34.000000
==> Total testing loss: 136.578375    Total testing error rate: 34.610000
==> Set learning rate: 0.010000
==> Training Epoch: 30
0.000000/1000.000000 ==> Training loss: 0.432192    Training error rate: 14.000000
50.000000/1000.000000 ==> Training loss: 0.696271    Training error rate: 16.000000
100.000000/1000.000000 ==> Training loss: 0.344217    Training error rate: 10.000000
150.000000/1000.000000 ==> Training loss: 0.482460    Training error rate: 16.000000
200.000000/1000.000000 ==> Training loss: 0.463526    Training error rate: 12.000000
250.000000/1000.000000 ==> Training loss: 0.573578    Training error rate: 16.000000
300.000000/1000.000000 ==> Training loss: 0.561832    Training error rate: 16.000000
350.000000/1000.000000 ==> Training loss: 0.486768    Training error rate: 18.000000
400.000000/1000.000000 ==> Training loss: 0.749933    Training error rate: 24.000000
450.000000/1000.000000 ==> Training loss: 0.506365    Training error rate: 14.000000
500.000000/1000.000000 ==> Training loss: 0.461061    Training error rate: 18.000000
550.000000/1000.000000 ==> Training loss: 0.723420    Training error rate: 20.000000
600.000000/1000.000000 ==> Training loss: 0.350758    Training error rate: 12.000000
650.000000/1000.000000 ==> Training loss: 0.620386    Training error rate: 22.000000
700.000000/1000.000000 ==> Training loss: 0.707178    Training error rate: 20.000000
750.000000/1000.000000 ==> Training loss: 0.669984    Training error rate: 26.000000
800.000000/1000.000000 ==> Training loss: 0.607139    Training error rate: 22.000000
850.000000/1000.000000 ==> Training loss: 0.386455    Training error rate: 4.000000
900.000000/1000.000000 ==> Training loss: 0.461845    Training error rate: 14.000000
950.000000/1000.000000 ==> Training loss: 1.043236    Training error rate: 30.000000
==> Total training loss: 580.119895    Total training error rate: 18.102000
==> Testing Epoch: 30
0.000000/100.000000 ==> Testing loss: 1.407333    Testing error rate: 36.000000
50.000000/100.000000 ==> Testing loss: 1.478549    Testing error rate: 38.000000
==> Total testing loss: 133.307863    Total testing error rate: 34.070000
==> Set learning rate: 0.010000
==> Training Epoch: 31
0.000000/1000.000000 ==> Training loss: 0.933336    Training error rate: 28.000000
50.000000/1000.000000 ==> Training loss: 0.665959    Training error rate: 16.000000
100.000000/1000.000000 ==> Training loss: 0.518665    Training error rate: 16.000000
150.000000/1000.000000 ==> Training loss: 0.516074    Training error rate: 18.000000
200.000000/1000.000000 ==> Training loss: 0.488049    Training error rate: 10.000000
250.000000/1000.000000 ==> Training loss: 0.512996    Training error rate: 20.000000
300.000000/1000.000000 ==> Training loss: 0.604276    Training error rate: 22.000000
350.000000/1000.000000 ==> Training loss: 0.664519    Training error rate: 24.000000
400.000000/1000.000000 ==> Training loss: 0.501880    Training error rate: 16.000000
450.000000/1000.000000 ==> Training loss: 0.619464    Training error rate: 18.000000
500.000000/1000.000000 ==> Training loss: 0.641199    Training error rate: 18.000000
550.000000/1000.000000 ==> Training loss: 0.799648    Training error rate: 22.000000
600.000000/1000.000000 ==> Training loss: 0.793716    Training error rate: 28.000000
650.000000/1000.000000 ==> Training loss: 0.618385    Training error rate: 16.000000
700.000000/1000.000000 ==> Training loss: 0.689100    Training error rate: 14.000000
750.000000/1000.000000 ==> Training loss: 0.532161    Training error rate: 16.000000
800.000000/1000.000000 ==> Training loss: 0.681722    Training error rate: 18.000000
850.000000/1000.000000 ==> Training loss: 0.520350    Training error rate: 14.000000
900.000000/1000.000000 ==> Training loss: 0.428542    Training error rate: 16.000000
950.000000/1000.000000 ==> Training loss: 0.699712    Training error rate: 28.000000
==> Total training loss: 556.668127    Total training error rate: 17.194000
==> Testing Epoch: 31
0.000000/100.000000 ==> Testing loss: 1.308931    Testing error rate: 31.000000
50.000000/100.000000 ==> Testing loss: 1.408145    Testing error rate: 36.000000
==> Total testing loss: 131.076372    Total testing error rate: 33.720000
==> Set learning rate: 0.010000
==> Training Epoch: 32
0.000000/1000.000000 ==> Training loss: 0.541996    Training error rate: 18.000000
50.000000/1000.000000 ==> Training loss: 0.489291    Training error rate: 22.000000
100.000000/1000.000000 ==> Training loss: 0.413593    Training error rate: 14.000000
150.000000/1000.000000 ==> Training loss: 0.266869    Training error rate: 8.000000
200.000000/1000.000000 ==> Training loss: 0.469570    Training error rate: 12.000000
250.000000/1000.000000 ==> Training loss: 0.575347    Training error rate: 22.000000
300.000000/1000.000000 ==> Training loss: 0.475427    Training error rate: 18.000000
350.000000/1000.000000 ==> Training loss: 0.517246    Training error rate: 12.000000
400.000000/1000.000000 ==> Training loss: 0.689512    Training error rate: 20.000000
450.000000/1000.000000 ==> Training loss: 0.446544    Training error rate: 14.000000
500.000000/1000.000000 ==> Training loss: 0.578767    Training error rate: 16.000000
550.000000/1000.000000 ==> Training loss: 0.400085    Training error rate: 14.000000
600.000000/1000.000000 ==> Training loss: 0.563599    Training error rate: 18.000000
650.000000/1000.000000 ==> Training loss: 0.565112    Training error rate: 22.000000
700.000000/1000.000000 ==> Training loss: 0.598149    Training error rate: 18.000000
750.000000/1000.000000 ==> Training loss: 0.476537    Training error rate: 16.000000
800.000000/1000.000000 ==> Training loss: 0.638925    Training error rate: 22.000000
850.000000/1000.000000 ==> Training loss: 0.669442    Training error rate: 24.000000
900.000000/1000.000000 ==> Training loss: 0.512418    Training error rate: 20.000000
950.000000/1000.000000 ==> Training loss: 0.712717    Training error rate: 20.000000
==> Total training loss: 549.285563    Total training error rate: 17.156000
==> Testing Epoch: 32
0.000000/100.000000 ==> Testing loss: 1.351614    Testing error rate: 35.000000
50.000000/100.000000 ==> Testing loss: 1.312277    Testing error rate: 38.000000
==> Total testing loss: 130.940722    Total testing error rate: 33.820000
==> Set learning rate: 0.010000
==> Training Epoch: 33
0.000000/1000.000000 ==> Training loss: 0.206199    Training error rate: 6.000000
50.000000/1000.000000 ==> Training loss: 0.254087    Training error rate: 4.000000
100.000000/1000.000000 ==> Training loss: 0.363210    Training error rate: 8.000000
150.000000/1000.000000 ==> Training loss: 0.519858    Training error rate: 18.000000
200.000000/1000.000000 ==> Training loss: 0.396009    Training error rate: 10.000000
250.000000/1000.000000 ==> Training loss: 0.421679    Training error rate: 16.000000
300.000000/1000.000000 ==> Training loss: 0.526622    Training error rate: 16.000000
350.000000/1000.000000 ==> Training loss: 0.676278    Training error rate: 28.000000
400.000000/1000.000000 ==> Training loss: 0.551814    Training error rate: 22.000000
450.000000/1000.000000 ==> Training loss: 0.305639    Training error rate: 10.000000
500.000000/1000.000000 ==> Training loss: 0.597916    Training error rate: 18.000000
550.000000/1000.000000 ==> Training loss: 0.733547    Training error rate: 22.000000
600.000000/1000.000000 ==> Training loss: 0.516091    Training error rate: 16.000000
650.000000/1000.000000 ==> Training loss: 0.261298    Training error rate: 6.000000
700.000000/1000.000000 ==> Training loss: 0.421495    Training error rate: 18.000000
750.000000/1000.000000 ==> Training loss: 0.901325    Training error rate: 22.000000
800.000000/1000.000000 ==> Training loss: 0.658560    Training error rate: 20.000000
850.000000/1000.000000 ==> Training loss: 0.469124    Training error rate: 14.000000
900.000000/1000.000000 ==> Training loss: 0.594396    Training error rate: 14.000000
950.000000/1000.000000 ==> Training loss: 0.498610    Training error rate: 16.000000
==> Total training loss: 532.831997    Total training error rate: 16.562000
==> Testing Epoch: 33
0.000000/100.000000 ==> Testing loss: 1.242313    Testing error rate: 35.000000
50.000000/100.000000 ==> Testing loss: 1.563501    Testing error rate: 36.000000
==> Total testing loss: 130.472184    Total testing error rate: 33.710000
==> Set learning rate: 0.010000
==> Training Epoch: 34
0.000000/1000.000000 ==> Training loss: 0.413926    Training error rate: 18.000000
50.000000/1000.000000 ==> Training loss: 0.416978    Training error rate: 14.000000
100.000000/1000.000000 ==> Training loss: 0.275623    Training error rate: 8.000000
150.000000/1000.000000 ==> Training loss: 0.670594    Training error rate: 18.000000
200.000000/1000.000000 ==> Training loss: 0.447582    Training error rate: 14.000000
250.000000/1000.000000 ==> Training loss: 0.476509    Training error rate: 12.000000
300.000000/1000.000000 ==> Training loss: 0.276328    Training error rate: 10.000000
350.000000/1000.000000 ==> Training loss: 0.344019    Training error rate: 10.000000
400.000000/1000.000000 ==> Training loss: 0.800767    Training error rate: 22.000000
450.000000/1000.000000 ==> Training loss: 0.550810    Training error rate: 14.000000
500.000000/1000.000000 ==> Training loss: 0.399276    Training error rate: 10.000000
550.000000/1000.000000 ==> Training loss: 0.840257    Training error rate: 28.000000
600.000000/1000.000000 ==> Training loss: 0.776445    Training error rate: 24.000000
650.000000/1000.000000 ==> Training loss: 0.343957    Training error rate: 12.000000
700.000000/1000.000000 ==> Training loss: 0.613229    Training error rate: 20.000000
750.000000/1000.000000 ==> Training loss: 0.536797    Training error rate: 16.000000
800.000000/1000.000000 ==> Training loss: 0.630215    Training error rate: 22.000000
850.000000/1000.000000 ==> Training loss: 0.621928    Training error rate: 22.000000
900.000000/1000.000000 ==> Training loss: 0.367973    Training error rate: 8.000000
950.000000/1000.000000 ==> Training loss: 0.576851    Training error rate: 18.000000
==> Total training loss: 524.150229    Total training error rate: 16.326000
==> Testing Epoch: 34
0.000000/100.000000 ==> Testing loss: 1.128772    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.330622    Testing error rate: 30.000000
==> Total testing loss: 133.066347    Total testing error rate: 33.550000
==> Set learning rate: 0.010000
==> Training Epoch: 35
0.000000/1000.000000 ==> Training loss: 0.353274    Training error rate: 12.000000
50.000000/1000.000000 ==> Training loss: 0.339722    Training error rate: 14.000000
100.000000/1000.000000 ==> Training loss: 0.269555    Training error rate: 4.000000
150.000000/1000.000000 ==> Training loss: 0.642366    Training error rate: 24.000000
200.000000/1000.000000 ==> Training loss: 0.365042    Training error rate: 16.000000
250.000000/1000.000000 ==> Training loss: 0.508456    Training error rate: 20.000000
300.000000/1000.000000 ==> Training loss: 0.543072    Training error rate: 22.000000
350.000000/1000.000000 ==> Training loss: 0.296753    Training error rate: 12.000000
400.000000/1000.000000 ==> Training loss: 0.422076    Training error rate: 14.000000
450.000000/1000.000000 ==> Training loss: 0.570508    Training error rate: 16.000000
500.000000/1000.000000 ==> Training loss: 0.648943    Training error rate: 22.000000
550.000000/1000.000000 ==> Training loss: 0.620867    Training error rate: 18.000000
600.000000/1000.000000 ==> Training loss: 0.470650    Training error rate: 16.000000
650.000000/1000.000000 ==> Training loss: 0.501985    Training error rate: 12.000000
700.000000/1000.000000 ==> Training loss: 0.904132    Training error rate: 20.000000
750.000000/1000.000000 ==> Training loss: 0.837771    Training error rate: 24.000000
800.000000/1000.000000 ==> Training loss: 0.559335    Training error rate: 16.000000
850.000000/1000.000000 ==> Training loss: 0.636658    Training error rate: 22.000000
900.000000/1000.000000 ==> Training loss: 0.723546    Training error rate: 22.000000
950.000000/1000.000000 ==> Training loss: 0.458572    Training error rate: 14.000000
==> Total training loss: 510.744326    Total training error rate: 15.994000
==> Testing Epoch: 35
0.000000/100.000000 ==> Testing loss: 1.450640    Testing error rate: 35.000000
50.000000/100.000000 ==> Testing loss: 1.695081    Testing error rate: 37.000000
==> Total testing loss: 132.702970    Total testing error rate: 33.370000
==> Set learning rate: 0.010000
==> Training Epoch: 36
0.000000/1000.000000 ==> Training loss: 0.294738    Training error rate: 6.000000
50.000000/1000.000000 ==> Training loss: 0.500434    Training error rate: 16.000000
100.000000/1000.000000 ==> Training loss: 0.625152    Training error rate: 16.000000
150.000000/1000.000000 ==> Training loss: 0.389946    Training error rate: 10.000000
200.000000/1000.000000 ==> Training loss: 0.285031    Training error rate: 14.000000
250.000000/1000.000000 ==> Training loss: 0.625696    Training error rate: 22.000000
300.000000/1000.000000 ==> Training loss: 0.446970    Training error rate: 16.000000
350.000000/1000.000000 ==> Training loss: 0.585388    Training error rate: 24.000000
400.000000/1000.000000 ==> Training loss: 0.394307    Training error rate: 12.000000
450.000000/1000.000000 ==> Training loss: 0.468235    Training error rate: 12.000000
500.000000/1000.000000 ==> Training loss: 0.549866    Training error rate: 14.000000
550.000000/1000.000000 ==> Training loss: 0.457948    Training error rate: 10.000000
600.000000/1000.000000 ==> Training loss: 0.403351    Training error rate: 18.000000
650.000000/1000.000000 ==> Training loss: 0.354323    Training error rate: 10.000000
700.000000/1000.000000 ==> Training loss: 0.286010    Training error rate: 12.000000
750.000000/1000.000000 ==> Training loss: 0.342997    Training error rate: 10.000000
800.000000/1000.000000 ==> Training loss: 0.341695    Training error rate: 6.000000
850.000000/1000.000000 ==> Training loss: 0.503265    Training error rate: 20.000000
900.000000/1000.000000 ==> Training loss: 0.501186    Training error rate: 12.000000
950.000000/1000.000000 ==> Training loss: 0.553430    Training error rate: 20.000000
==> Total training loss: 494.874672    Total training error rate: 15.406000
==> Testing Epoch: 36
0.000000/100.000000 ==> Testing loss: 1.275735    Testing error rate: 37.000000
50.000000/100.000000 ==> Testing loss: 1.382798    Testing error rate: 36.000000
==> Total testing loss: 132.772307    Total testing error rate: 33.370000
==> Set learning rate: 0.010000
==> Training Epoch: 37
0.000000/1000.000000 ==> Training loss: 0.337201    Training error rate: 10.000000
50.000000/1000.000000 ==> Training loss: 0.260766    Training error rate: 6.000000
100.000000/1000.000000 ==> Training loss: 0.360013    Training error rate: 8.000000
150.000000/1000.000000 ==> Training loss: 0.437546    Training error rate: 10.000000
200.000000/1000.000000 ==> Training loss: 0.367581    Training error rate: 16.000000
250.000000/1000.000000 ==> Training loss: 0.527081    Training error rate: 18.000000
300.000000/1000.000000 ==> Training loss: 0.320443    Training error rate: 6.000000
350.000000/1000.000000 ==> Training loss: 0.264491    Training error rate: 8.000000
400.000000/1000.000000 ==> Training loss: 0.297973    Training error rate: 10.000000
450.000000/1000.000000 ==> Training loss: 0.618163    Training error rate: 16.000000
500.000000/1000.000000 ==> Training loss: 0.325274    Training error rate: 16.000000
550.000000/1000.000000 ==> Training loss: 0.669437    Training error rate: 18.000000
600.000000/1000.000000 ==> Training loss: 0.394505    Training error rate: 18.000000
650.000000/1000.000000 ==> Training loss: 0.263605    Training error rate: 10.000000
700.000000/1000.000000 ==> Training loss: 0.461364    Training error rate: 14.000000
750.000000/1000.000000 ==> Training loss: 0.286392    Training error rate: 8.000000
800.000000/1000.000000 ==> Training loss: 0.521193    Training error rate: 18.000000
850.000000/1000.000000 ==> Training loss: 0.609075    Training error rate: 16.000000
900.000000/1000.000000 ==> Training loss: 0.675492    Training error rate: 22.000000
950.000000/1000.000000 ==> Training loss: 0.572425    Training error rate: 18.000000
==> Total training loss: 492.121956    Total training error rate: 15.486000
==> Testing Epoch: 37
0.000000/100.000000 ==> Testing loss: 1.462802    Testing error rate: 39.000000
50.000000/100.000000 ==> Testing loss: 1.751405    Testing error rate: 37.000000
==> Total testing loss: 141.743365    Total testing error rate: 34.750000
==> Set learning rate: 0.010000
==> Training Epoch: 38
0.000000/1000.000000 ==> Training loss: 0.379425    Training error rate: 10.000000
50.000000/1000.000000 ==> Training loss: 0.445211    Training error rate: 12.000000
100.000000/1000.000000 ==> Training loss: 0.537386    Training error rate: 12.000000
150.000000/1000.000000 ==> Training loss: 0.589701    Training error rate: 22.000000
200.000000/1000.000000 ==> Training loss: 0.684603    Training error rate: 20.000000
250.000000/1000.000000 ==> Training loss: 0.382033    Training error rate: 12.000000
300.000000/1000.000000 ==> Training loss: 0.496578    Training error rate: 18.000000
350.000000/1000.000000 ==> Training loss: 0.353364    Training error rate: 10.000000
400.000000/1000.000000 ==> Training loss: 0.300115    Training error rate: 10.000000
450.000000/1000.000000 ==> Training loss: 0.498817    Training error rate: 18.000000
500.000000/1000.000000 ==> Training loss: 0.582062    Training error rate: 16.000000
550.000000/1000.000000 ==> Training loss: 0.632653    Training error rate: 22.000000
600.000000/1000.000000 ==> Training loss: 0.625096    Training error rate: 14.000000
650.000000/1000.000000 ==> Training loss: 0.545277    Training error rate: 16.000000
700.000000/1000.000000 ==> Training loss: 0.549351    Training error rate: 18.000000
750.000000/1000.000000 ==> Training loss: 0.428893    Training error rate: 20.000000
800.000000/1000.000000 ==> Training loss: 0.667272    Training error rate: 20.000000
850.000000/1000.000000 ==> Training loss: 0.461554    Training error rate: 18.000000
900.000000/1000.000000 ==> Training loss: 0.448872    Training error rate: 12.000000
950.000000/1000.000000 ==> Training loss: 0.425138    Training error rate: 14.000000
==> Total training loss: 489.372964    Total training error rate: 15.398000
==> Testing Epoch: 38
0.000000/100.000000 ==> Testing loss: 1.232594    Testing error rate: 31.000000
50.000000/100.000000 ==> Testing loss: 1.599783    Testing error rate: 39.000000
==> Total testing loss: 135.571918    Total testing error rate: 33.900000
==> Set learning rate: 0.010000
==> Training Epoch: 39
0.000000/1000.000000 ==> Training loss: 0.482280    Training error rate: 18.000000
50.000000/1000.000000 ==> Training loss: 0.408210    Training error rate: 10.000000
100.000000/1000.000000 ==> Training loss: 0.363052    Training error rate: 12.000000
150.000000/1000.000000 ==> Training loss: 0.309565    Training error rate: 8.000000
200.000000/1000.000000 ==> Training loss: 0.343229    Training error rate: 8.000000
250.000000/1000.000000 ==> Training loss: 0.432470    Training error rate: 14.000000
300.000000/1000.000000 ==> Training loss: 0.179442    Training error rate: 4.000000
350.000000/1000.000000 ==> Training loss: 0.515397    Training error rate: 14.000000
400.000000/1000.000000 ==> Training loss: 0.436795    Training error rate: 12.000000
450.000000/1000.000000 ==> Training loss: 0.594555    Training error rate: 18.000000
500.000000/1000.000000 ==> Training loss: 0.368789    Training error rate: 10.000000
550.000000/1000.000000 ==> Training loss: 0.423642    Training error rate: 10.000000
600.000000/1000.000000 ==> Training loss: 0.358765    Training error rate: 12.000000
650.000000/1000.000000 ==> Training loss: 0.435897    Training error rate: 12.000000
700.000000/1000.000000 ==> Training loss: 0.384235    Training error rate: 10.000000
750.000000/1000.000000 ==> Training loss: 0.506003    Training error rate: 14.000000
800.000000/1000.000000 ==> Training loss: 0.731243    Training error rate: 20.000000
850.000000/1000.000000 ==> Training loss: 0.500502    Training error rate: 18.000000
900.000000/1000.000000 ==> Training loss: 0.469634    Training error rate: 12.000000
950.000000/1000.000000 ==> Training loss: 0.465383    Training error rate: 14.000000
==> Total training loss: 484.977165    Total training error rate: 15.168000
==> Testing Epoch: 39
0.000000/100.000000 ==> Testing loss: 1.431717    Testing error rate: 34.000000
50.000000/100.000000 ==> Testing loss: 1.511400    Testing error rate: 33.000000
==> Total testing loss: 131.981991    Total testing error rate: 32.330000
==> Saving checkpoint..
==> Set learning rate: 0.010000
==> Training Epoch: 40
0.000000/1000.000000 ==> Training loss: 0.516245    Training error rate: 20.000000
50.000000/1000.000000 ==> Training loss: 0.258235    Training error rate: 10.000000
100.000000/1000.000000 ==> Training loss: 0.192280    Training error rate: 8.000000
150.000000/1000.000000 ==> Training loss: 0.515175    Training error rate: 20.000000
200.000000/1000.000000 ==> Training loss: 0.504372    Training error rate: 18.000000
250.000000/1000.000000 ==> Training loss: 0.300741    Training error rate: 12.000000
300.000000/1000.000000 ==> Training loss: 0.166698    Training error rate: 4.000000
350.000000/1000.000000 ==> Training loss: 0.355714    Training error rate: 14.000000
400.000000/1000.000000 ==> Training loss: 0.442949    Training error rate: 8.000000
450.000000/1000.000000 ==> Training loss: 0.419406    Training error rate: 14.000000
500.000000/1000.000000 ==> Training loss: 0.267476    Training error rate: 8.000000
550.000000/1000.000000 ==> Training loss: 0.543295    Training error rate: 14.000000
600.000000/1000.000000 ==> Training loss: 0.647877    Training error rate: 20.000000
650.000000/1000.000000 ==> Training loss: 0.387445    Training error rate: 12.000000
700.000000/1000.000000 ==> Training loss: 0.471836    Training error rate: 12.000000
750.000000/1000.000000 ==> Training loss: 0.394333    Training error rate: 12.000000
800.000000/1000.000000 ==> Training loss: 0.419846    Training error rate: 10.000000
850.000000/1000.000000 ==> Training loss: 0.621601    Training error rate: 18.000000
900.000000/1000.000000 ==> Training loss: 0.391723    Training error rate: 12.000000
950.000000/1000.000000 ==> Training loss: 0.789420    Training error rate: 26.000000
==> Total training loss: 459.934845    Total training error rate: 14.470000
==> Testing Epoch: 40
0.000000/100.000000 ==> Testing loss: 1.273600    Testing error rate: 31.000000
50.000000/100.000000 ==> Testing loss: 1.349132    Testing error rate: 33.000000
==> Total testing loss: 131.573008    Total testing error rate: 33.160000
==> Set learning rate: 0.010000
==> Training Epoch: 41
0.000000/1000.000000 ==> Training loss: 0.385523    Training error rate: 10.000000
50.000000/1000.000000 ==> Training loss: 0.351703    Training error rate: 12.000000
100.000000/1000.000000 ==> Training loss: 0.459482    Training error rate: 18.000000
150.000000/1000.000000 ==> Training loss: 0.379240    Training error rate: 10.000000
200.000000/1000.000000 ==> Training loss: 0.153118    Training error rate: 4.000000
250.000000/1000.000000 ==> Training loss: 0.835757    Training error rate: 22.000000
300.000000/1000.000000 ==> Training loss: 0.348081    Training error rate: 14.000000
350.000000/1000.000000 ==> Training loss: 0.386175    Training error rate: 12.000000
400.000000/1000.000000 ==> Training loss: 0.412855    Training error rate: 14.000000
450.000000/1000.000000 ==> Training loss: 0.530109    Training error rate: 18.000000
500.000000/1000.000000 ==> Training loss: 0.428910    Training error rate: 10.000000
550.000000/1000.000000 ==> Training loss: 0.467326    Training error rate: 20.000000
600.000000/1000.000000 ==> Training loss: 0.357851    Training error rate: 14.000000
650.000000/1000.000000 ==> Training loss: 0.520982    Training error rate: 18.000000
700.000000/1000.000000 ==> Training loss: 0.281159    Training error rate: 4.000000
750.000000/1000.000000 ==> Training loss: 0.678312    Training error rate: 18.000000
800.000000/1000.000000 ==> Training loss: 0.610796    Training error rate: 14.000000
850.000000/1000.000000 ==> Training loss: 0.516481    Training error rate: 16.000000
900.000000/1000.000000 ==> Training loss: 0.677511    Training error rate: 20.000000
950.000000/1000.000000 ==> Training loss: 0.284510    Training error rate: 8.000000
==> Total training loss: 457.367274    Total training error rate: 14.262000
==> Testing Epoch: 41
0.000000/100.000000 ==> Testing loss: 1.565150    Testing error rate: 38.000000
50.000000/100.000000 ==> Testing loss: 1.502286    Testing error rate: 37.000000
==> Total testing loss: 145.781593    Total testing error rate: 35.200000
==> Set learning rate: 0.010000
==> Training Epoch: 42
0.000000/1000.000000 ==> Training loss: 0.447783    Training error rate: 16.000000
50.000000/1000.000000 ==> Training loss: 0.507554    Training error rate: 16.000000
100.000000/1000.000000 ==> Training loss: 0.399550    Training error rate: 12.000000
150.000000/1000.000000 ==> Training loss: 0.175111    Training error rate: 4.000000
200.000000/1000.000000 ==> Training loss: 0.494469    Training error rate: 18.000000
250.000000/1000.000000 ==> Training loss: 0.411575    Training error rate: 16.000000
300.000000/1000.000000 ==> Training loss: 0.460737    Training error rate: 14.000000
350.000000/1000.000000 ==> Training loss: 0.345031    Training error rate: 10.000000
400.000000/1000.000000 ==> Training loss: 0.317495    Training error rate: 10.000000
450.000000/1000.000000 ==> Training loss: 0.307340    Training error rate: 10.000000
500.000000/1000.000000 ==> Training loss: 0.441510    Training error rate: 16.000000
550.000000/1000.000000 ==> Training loss: 0.255742    Training error rate: 6.000000
600.000000/1000.000000 ==> Training loss: 0.400195    Training error rate: 10.000000
650.000000/1000.000000 ==> Training loss: 0.215726    Training error rate: 8.000000
700.000000/1000.000000 ==> Training loss: 0.474652    Training error rate: 14.000000
750.000000/1000.000000 ==> Training loss: 0.514602    Training error rate: 14.000000
800.000000/1000.000000 ==> Training loss: 0.582615    Training error rate: 18.000000
850.000000/1000.000000 ==> Training loss: 0.860290    Training error rate: 26.000000
900.000000/1000.000000 ==> Training loss: 0.355220    Training error rate: 14.000000
950.000000/1000.000000 ==> Training loss: 0.349310    Training error rate: 10.000000
==> Total training loss: 458.349145    Total training error rate: 14.304000
==> Testing Epoch: 42
0.000000/100.000000 ==> Testing loss: 1.240103    Testing error rate: 33.000000
50.000000/100.000000 ==> Testing loss: 1.283614    Testing error rate: 31.000000
==> Total testing loss: 133.127433    Total testing error rate: 32.750000
==> Set learning rate: 0.010000
==> Training Epoch: 43
0.000000/1000.000000 ==> Training loss: 0.407628    Training error rate: 10.000000
50.000000/1000.000000 ==> Training loss: 0.363169    Training error rate: 10.000000
100.000000/1000.000000 ==> Training loss: 0.406523    Training error rate: 8.000000
150.000000/1000.000000 ==> Training loss: 0.445032    Training error rate: 18.000000
200.000000/1000.000000 ==> Training loss: 0.478701    Training error rate: 20.000000
250.000000/1000.000000 ==> Training loss: 0.461425    Training error rate: 10.000000
300.000000/1000.000000 ==> Training loss: 0.233501    Training error rate: 6.000000
350.000000/1000.000000 ==> Training loss: 0.709402    Training error rate: 22.000000
400.000000/1000.000000 ==> Training loss: 0.401277    Training error rate: 10.000000
450.000000/1000.000000 ==> Training loss: 0.347963    Training error rate: 10.000000
500.000000/1000.000000 ==> Training loss: 0.640381    Training error rate: 18.000000
550.000000/1000.000000 ==> Training loss: 0.682814    Training error rate: 16.000000
600.000000/1000.000000 ==> Training loss: 0.511109    Training error rate: 16.000000
650.000000/1000.000000 ==> Training loss: 0.277682    Training error rate: 6.000000
700.000000/1000.000000 ==> Training loss: 0.619458    Training error rate: 22.000000
750.000000/1000.000000 ==> Training loss: 0.470774    Training error rate: 14.000000
800.000000/1000.000000 ==> Training loss: 0.753090    Training error rate: 20.000000
850.000000/1000.000000 ==> Training loss: 0.678251    Training error rate: 20.000000
900.000000/1000.000000 ==> Training loss: 0.416450    Training error rate: 10.000000
950.000000/1000.000000 ==> Training loss: 0.444635    Training error rate: 12.000000
==> Total training loss: 445.448049    Total training error rate: 14.012000
==> Testing Epoch: 43
0.000000/100.000000 ==> Testing loss: 1.103271    Testing error rate: 31.000000
50.000000/100.000000 ==> Testing loss: 1.495779    Testing error rate: 32.000000
==> Total testing loss: 133.166791    Total testing error rate: 32.380000
==> Set learning rate: 0.010000
==> Training Epoch: 44
0.000000/1000.000000 ==> Training loss: 0.420814    Training error rate: 16.000000
50.000000/1000.000000 ==> Training loss: 0.267675    Training error rate: 10.000000
100.000000/1000.000000 ==> Training loss: 0.444450    Training error rate: 24.000000
150.000000/1000.000000 ==> Training loss: 0.295586    Training error rate: 12.000000
200.000000/1000.000000 ==> Training loss: 0.277259    Training error rate: 8.000000
250.000000/1000.000000 ==> Training loss: 0.507248    Training error rate: 20.000000
300.000000/1000.000000 ==> Training loss: 0.311354    Training error rate: 8.000000
350.000000/1000.000000 ==> Training loss: 0.371448    Training error rate: 6.000000
400.000000/1000.000000 ==> Training loss: 0.198044    Training error rate: 6.000000
450.000000/1000.000000 ==> Training loss: 0.387329    Training error rate: 12.000000
500.000000/1000.000000 ==> Training loss: 0.251169    Training error rate: 12.000000
550.000000/1000.000000 ==> Training loss: 0.376532    Training error rate: 14.000000
600.000000/1000.000000 ==> Training loss: 0.378495    Training error rate: 10.000000
650.000000/1000.000000 ==> Training loss: 0.729867    Training error rate: 22.000000
700.000000/1000.000000 ==> Training loss: 0.638411    Training error rate: 20.000000
750.000000/1000.000000 ==> Training loss: 0.379608    Training error rate: 10.000000
800.000000/1000.000000 ==> Training loss: 0.624118    Training error rate: 16.000000
850.000000/1000.000000 ==> Training loss: 0.635596    Training error rate: 22.000000
900.000000/1000.000000 ==> Training loss: 0.462936    Training error rate: 14.000000
950.000000/1000.000000 ==> Training loss: 0.661594    Training error rate: 20.000000
==> Total training loss: 434.130503    Total training error rate: 13.528000
==> Testing Epoch: 44
0.000000/100.000000 ==> Testing loss: 1.186848    Testing error rate: 31.000000
50.000000/100.000000 ==> Testing loss: 1.270207    Testing error rate: 27.000000
==> Total testing loss: 132.359291    Total testing error rate: 32.350000
==> Set learning rate: 0.010000
==> Training Epoch: 45
0.000000/1000.000000 ==> Training loss: 0.328984    Training error rate: 8.000000
50.000000/1000.000000 ==> Training loss: 0.446915    Training error rate: 16.000000
100.000000/1000.000000 ==> Training loss: 0.443802    Training error rate: 16.000000
150.000000/1000.000000 ==> Training loss: 0.412737    Training error rate: 16.000000
200.000000/1000.000000 ==> Training loss: 0.406945    Training error rate: 16.000000
250.000000/1000.000000 ==> Training loss: 0.540849    Training error rate: 16.000000
300.000000/1000.000000 ==> Training loss: 0.437300    Training error rate: 14.000000
350.000000/1000.000000 ==> Training loss: 0.387742    Training error rate: 12.000000
400.000000/1000.000000 ==> Training loss: 0.442431    Training error rate: 10.000000
450.000000/1000.000000 ==> Training loss: 0.226669    Training error rate: 6.000000
500.000000/1000.000000 ==> Training loss: 0.332242    Training error rate: 6.000000
550.000000/1000.000000 ==> Training loss: 0.377229    Training error rate: 8.000000
600.000000/1000.000000 ==> Training loss: 0.464948    Training error rate: 16.000000
650.000000/1000.000000 ==> Training loss: 0.452944    Training error rate: 12.000000
700.000000/1000.000000 ==> Training loss: 0.306169    Training error rate: 6.000000
750.000000/1000.000000 ==> Training loss: 0.478642    Training error rate: 18.000000
800.000000/1000.000000 ==> Training loss: 0.319942    Training error rate: 6.000000
850.000000/1000.000000 ==> Training loss: 0.553532    Training error rate: 16.000000
900.000000/1000.000000 ==> Training loss: 0.587574    Training error rate: 16.000000
950.000000/1000.000000 ==> Training loss: 0.534491    Training error rate: 18.000000
==> Total training loss: 437.697745    Total training error rate: 13.650000
==> Testing Epoch: 45
0.000000/100.000000 ==> Testing loss: 1.253525    Testing error rate: 30.000000
50.000000/100.000000 ==> Testing loss: 1.664342    Testing error rate: 34.000000
==> Total testing loss: 141.333672    Total testing error rate: 34.010000
==> Set learning rate: 0.010000
==> Training Epoch: 46
0.000000/1000.000000 ==> Training loss: 0.448344    Training error rate: 16.000000
50.000000/1000.000000 ==> Training loss: 0.341692    Training error rate: 8.000000
100.000000/1000.000000 ==> Training loss: 0.247026    Training error rate: 6.000000
150.000000/1000.000000 ==> Training loss: 0.642556    Training error rate: 18.000000
200.000000/1000.000000 ==> Training loss: 0.567660    Training error rate: 18.000000
250.000000/1000.000000 ==> Training loss: 0.363332    Training error rate: 12.000000
300.000000/1000.000000 ==> Training loss: 0.263142    Training error rate: 8.000000
350.000000/1000.000000 ==> Training loss: 0.266941    Training error rate: 6.000000
400.000000/1000.000000 ==> Training loss: 0.523745    Training error rate: 14.000000
450.000000/1000.000000 ==> Training loss: 0.180811    Training error rate: 4.000000
500.000000/1000.000000 ==> Training loss: 0.644012    Training error rate: 12.000000
550.000000/1000.000000 ==> Training loss: 0.490315    Training error rate: 10.000000
600.000000/1000.000000 ==> Training loss: 0.530464    Training error rate: 18.000000
650.000000/1000.000000 ==> Training loss: 0.331673    Training error rate: 16.000000
700.000000/1000.000000 ==> Training loss: 0.557476    Training error rate: 18.000000
750.000000/1000.000000 ==> Training loss: 0.325756    Training error rate: 8.000000
800.000000/1000.000000 ==> Training loss: 0.453926    Training error rate: 16.000000
850.000000/1000.000000 ==> Training loss: 0.301369    Training error rate: 10.000000
900.000000/1000.000000 ==> Training loss: 0.486275    Training error rate: 16.000000
950.000000/1000.000000 ==> Training loss: 0.403261    Training error rate: 18.000000
==> Total training loss: 415.736374    Total training error rate: 12.938000
==> Testing Epoch: 46
0.000000/100.000000 ==> Testing loss: 1.569226    Testing error rate: 33.000000
50.000000/100.000000 ==> Testing loss: 1.375253    Testing error rate: 32.000000
==> Total testing loss: 139.022945    Total testing error rate: 34.150000
==> Set learning rate: 0.010000
==> Training Epoch: 47
0.000000/1000.000000 ==> Training loss: 0.273760    Training error rate: 8.000000
50.000000/1000.000000 ==> Training loss: 0.232471    Training error rate: 6.000000
100.000000/1000.000000 ==> Training loss: 0.413816    Training error rate: 12.000000
150.000000/1000.000000 ==> Training loss: 0.212856    Training error rate: 6.000000
200.000000/1000.000000 ==> Training loss: 0.409772    Training error rate: 14.000000
250.000000/1000.000000 ==> Training loss: 0.321412    Training error rate: 12.000000
300.000000/1000.000000 ==> Training loss: 0.301139    Training error rate: 12.000000
350.000000/1000.000000 ==> Training loss: 0.522140    Training error rate: 12.000000
400.000000/1000.000000 ==> Training loss: 0.391707    Training error rate: 10.000000
450.000000/1000.000000 ==> Training loss: 0.386173    Training error rate: 18.000000
500.000000/1000.000000 ==> Training loss: 0.369504    Training error rate: 10.000000
550.000000/1000.000000 ==> Training loss: 0.419727    Training error rate: 14.000000
600.000000/1000.000000 ==> Training loss: 0.302983    Training error rate: 10.000000
650.000000/1000.000000 ==> Training loss: 0.364011    Training error rate: 14.000000
700.000000/1000.000000 ==> Training loss: 0.376625    Training error rate: 10.000000
750.000000/1000.000000 ==> Training loss: 0.461340    Training error rate: 14.000000
800.000000/1000.000000 ==> Training loss: 0.356588    Training error rate: 14.000000
850.000000/1000.000000 ==> Training loss: 0.371452    Training error rate: 10.000000
900.000000/1000.000000 ==> Training loss: 0.307265    Training error rate: 4.000000
950.000000/1000.000000 ==> Training loss: 0.444078    Training error rate: 12.000000
==> Total training loss: 421.733748    Total training error rate: 13.146000
==> Testing Epoch: 47
0.000000/100.000000 ==> Testing loss: 1.552274    Testing error rate: 42.000000
50.000000/100.000000 ==> Testing loss: 1.621663    Testing error rate: 38.000000
==> Total testing loss: 143.627619    Total testing error rate: 34.020000
==> Set learning rate: 0.010000
==> Training Epoch: 48
0.000000/1000.000000 ==> Training loss: 0.411648    Training error rate: 14.000000
50.000000/1000.000000 ==> Training loss: 0.500767    Training error rate: 14.000000
100.000000/1000.000000 ==> Training loss: 0.703638    Training error rate: 18.000000
150.000000/1000.000000 ==> Training loss: 0.716228    Training error rate: 20.000000
200.000000/1000.000000 ==> Training loss: 0.363816    Training error rate: 14.000000
250.000000/1000.000000 ==> Training loss: 0.400890    Training error rate: 14.000000
300.000000/1000.000000 ==> Training loss: 0.267895    Training error rate: 6.000000
350.000000/1000.000000 ==> Training loss: 0.627449    Training error rate: 20.000000
400.000000/1000.000000 ==> Training loss: 0.496896    Training error rate: 18.000000
450.000000/1000.000000 ==> Training loss: 0.355012    Training error rate: 8.000000
500.000000/1000.000000 ==> Training loss: 0.423941    Training error rate: 10.000000
550.000000/1000.000000 ==> Training loss: 0.221641    Training error rate: 6.000000
600.000000/1000.000000 ==> Training loss: 0.462071    Training error rate: 10.000000
650.000000/1000.000000 ==> Training loss: 0.407181    Training error rate: 18.000000
700.000000/1000.000000 ==> Training loss: 0.316542    Training error rate: 12.000000
750.000000/1000.000000 ==> Training loss: 0.356359    Training error rate: 8.000000
800.000000/1000.000000 ==> Training loss: 0.277970    Training error rate: 10.000000
850.000000/1000.000000 ==> Training loss: 0.566964    Training error rate: 14.000000
900.000000/1000.000000 ==> Training loss: 0.542634    Training error rate: 18.000000
950.000000/1000.000000 ==> Training loss: 0.516181    Training error rate: 14.000000
==> Total training loss: 413.289970    Total training error rate: 12.950000
==> Testing Epoch: 48
0.000000/100.000000 ==> Testing loss: 1.371323    Testing error rate: 33.000000
50.000000/100.000000 ==> Testing loss: 1.396171    Testing error rate: 32.000000
==> Total testing loss: 133.876138    Total testing error rate: 32.350000
==> Set learning rate: 0.010000
==> Training Epoch: 49
0.000000/1000.000000 ==> Training loss: 0.159713    Training error rate: 4.000000
50.000000/1000.000000 ==> Training loss: 0.360978    Training error rate: 14.000000
100.000000/1000.000000 ==> Training loss: 0.301528    Training error rate: 6.000000
150.000000/1000.000000 ==> Training loss: 0.233821    Training error rate: 8.000000
200.000000/1000.000000 ==> Training loss: 0.342310    Training error rate: 8.000000
250.000000/1000.000000 ==> Training loss: 0.393670    Training error rate: 14.000000
300.000000/1000.000000 ==> Training loss: 0.329143    Training error rate: 6.000000
350.000000/1000.000000 ==> Training loss: 0.438572    Training error rate: 24.000000
400.000000/1000.000000 ==> Training loss: 0.311705    Training error rate: 10.000000
450.000000/1000.000000 ==> Training loss: 0.422752    Training error rate: 12.000000
500.000000/1000.000000 ==> Training loss: 0.516457    Training error rate: 12.000000
550.000000/1000.000000 ==> Training loss: 0.515504    Training error rate: 16.000000
600.000000/1000.000000 ==> Training loss: 0.539739    Training error rate: 22.000000
650.000000/1000.000000 ==> Training loss: 0.508265    Training error rate: 18.000000
700.000000/1000.000000 ==> Training loss: 0.331867    Training error rate: 10.000000
750.000000/1000.000000 ==> Training loss: 0.294963    Training error rate: 12.000000
800.000000/1000.000000 ==> Training loss: 0.324144    Training error rate: 14.000000
850.000000/1000.000000 ==> Training loss: 0.257622    Training error rate: 10.000000
900.000000/1000.000000 ==> Training loss: 0.311846    Training error rate: 8.000000
950.000000/1000.000000 ==> Training loss: 0.397692    Training error rate: 14.000000
==> Total training loss: 410.801068    Total training error rate: 12.834000
==> Testing Epoch: 49
0.000000/100.000000 ==> Testing loss: 1.437872    Testing error rate: 38.000000
50.000000/100.000000 ==> Testing loss: 1.644069    Testing error rate: 39.000000
==> Total testing loss: 143.512910    Total testing error rate: 34.630000
==> Set learning rate: 0.001000
==> Training Epoch: 50
0.000000/1000.000000 ==> Training loss: 0.363151    Training error rate: 14.000000
50.000000/1000.000000 ==> Training loss: 0.400368    Training error rate: 20.000000
100.000000/1000.000000 ==> Training loss: 0.160668    Training error rate: 6.000000
150.000000/1000.000000 ==> Training loss: 0.163161    Training error rate: 6.000000
200.000000/1000.000000 ==> Training loss: 0.149516    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.177740    Training error rate: 4.000000
300.000000/1000.000000 ==> Training loss: 0.099991    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.081329    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.255314    Training error rate: 6.000000
450.000000/1000.000000 ==> Training loss: 0.134235    Training error rate: 4.000000
500.000000/1000.000000 ==> Training loss: 0.061352    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.188152    Training error rate: 6.000000
600.000000/1000.000000 ==> Training loss: 0.213330    Training error rate: 6.000000
650.000000/1000.000000 ==> Training loss: 0.336547    Training error rate: 8.000000
700.000000/1000.000000 ==> Training loss: 0.119114    Training error rate: 4.000000
750.000000/1000.000000 ==> Training loss: 0.072577    Training error rate: 2.000000
800.000000/1000.000000 ==> Training loss: 0.113504    Training error rate: 2.000000
850.000000/1000.000000 ==> Training loss: 0.181079    Training error rate: 6.000000
900.000000/1000.000000 ==> Training loss: 0.132618    Training error rate: 4.000000
950.000000/1000.000000 ==> Training loss: 0.103338    Training error rate: 0.000000
==> Total training loss: 182.224988    Total training error rate: 5.142000
==> Testing Epoch: 50
0.000000/100.000000 ==> Testing loss: 1.000939    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.295473    Testing error rate: 28.000000
==> Total testing loss: 99.608125    Total testing error rate: 25.670000
==> Saving checkpoint..
==> Set learning rate: 0.001000
==> Training Epoch: 51
0.000000/1000.000000 ==> Training loss: 0.148798    Training error rate: 4.000000
50.000000/1000.000000 ==> Training loss: 0.075471    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.139677    Training error rate: 4.000000
150.000000/1000.000000 ==> Training loss: 0.094704    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.062441    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.045353    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.117456    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.072929    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.097889    Training error rate: 4.000000
450.000000/1000.000000 ==> Training loss: 0.065155    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.115305    Training error rate: 4.000000
550.000000/1000.000000 ==> Training loss: 0.091198    Training error rate: 4.000000
600.000000/1000.000000 ==> Training loss: 0.100908    Training error rate: 4.000000
650.000000/1000.000000 ==> Training loss: 0.097469    Training error rate: 2.000000
700.000000/1000.000000 ==> Training loss: 0.061140    Training error rate: 2.000000
750.000000/1000.000000 ==> Training loss: 0.123548    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.110979    Training error rate: 2.000000
850.000000/1000.000000 ==> Training loss: 0.134570    Training error rate: 4.000000
900.000000/1000.000000 ==> Training loss: 0.094611    Training error rate: 4.000000
950.000000/1000.000000 ==> Training loss: 0.042895    Training error rate: 0.000000
==> Total training loss: 106.816391    Total training error rate: 2.618000
==> Testing Epoch: 51
0.000000/100.000000 ==> Testing loss: 0.991188    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.251977    Testing error rate: 28.000000
==> Total testing loss: 98.336707    Total testing error rate: 25.290000
==> Saving checkpoint..
==> Set learning rate: 0.001000
==> Training Epoch: 52
0.000000/1000.000000 ==> Training loss: 0.083425    Training error rate: 2.000000
50.000000/1000.000000 ==> Training loss: 0.039347    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.071480    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.087497    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.044653    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.073048    Training error rate: 2.000000
300.000000/1000.000000 ==> Training loss: 0.102320    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.097447    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.071268    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.059280    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.094114    Training error rate: 4.000000
550.000000/1000.000000 ==> Training loss: 0.078419    Training error rate: 2.000000
600.000000/1000.000000 ==> Training loss: 0.051939    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.084537    Training error rate: 4.000000
700.000000/1000.000000 ==> Training loss: 0.064093    Training error rate: 2.000000
750.000000/1000.000000 ==> Training loss: 0.059937    Training error rate: 2.000000
800.000000/1000.000000 ==> Training loss: 0.092410    Training error rate: 2.000000
850.000000/1000.000000 ==> Training loss: 0.069997    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.123265    Training error rate: 4.000000
950.000000/1000.000000 ==> Training loss: 0.064265    Training error rate: 0.000000
==> Total training loss: 86.719730    Total training error rate: 1.980000
==> Testing Epoch: 52
0.000000/100.000000 ==> Testing loss: 1.004865    Testing error rate: 25.000000
50.000000/100.000000 ==> Testing loss: 1.232787    Testing error rate: 27.000000
==> Total testing loss: 98.766235    Total testing error rate: 25.130000
==> Saving checkpoint..
==> Set learning rate: 0.001000
==> Training Epoch: 53
0.000000/1000.000000 ==> Training loss: 0.097770    Training error rate: 2.000000
50.000000/1000.000000 ==> Training loss: 0.058966    Training error rate: 2.000000
100.000000/1000.000000 ==> Training loss: 0.047442    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.084757    Training error rate: 4.000000
200.000000/1000.000000 ==> Training loss: 0.066086    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.071777    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.051934    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.063797    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.054078    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.075191    Training error rate: 2.000000
500.000000/1000.000000 ==> Training loss: 0.054202    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.077135    Training error rate: 2.000000
600.000000/1000.000000 ==> Training loss: 0.128735    Training error rate: 4.000000
650.000000/1000.000000 ==> Training loss: 0.117218    Training error rate: 4.000000
700.000000/1000.000000 ==> Training loss: 0.076610    Training error rate: 2.000000
750.000000/1000.000000 ==> Training loss: 0.035768    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.050944    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.028101    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.044252    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.051287    Training error rate: 0.000000
==> Total training loss: 72.626702    Total training error rate: 1.592000
==> Testing Epoch: 53
0.000000/100.000000 ==> Testing loss: 1.029713    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.256629    Testing error rate: 28.000000
==> Total testing loss: 99.149347    Total testing error rate: 24.990000
==> Saving checkpoint..
==> Set learning rate: 0.001000
==> Training Epoch: 54
0.000000/1000.000000 ==> Training loss: 0.085773    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.017194    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.055755    Training error rate: 2.000000
150.000000/1000.000000 ==> Training loss: 0.070460    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.069804    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.095976    Training error rate: 2.000000
300.000000/1000.000000 ==> Training loss: 0.053603    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.040011    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.040427    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.017870    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.051961    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.056205    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.059164    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.034540    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.039686    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.026614    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.048089    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.025097    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.014763    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.047724    Training error rate: 2.000000
==> Total training loss: 64.289054    Total training error rate: 1.334000
==> Testing Epoch: 54
0.000000/100.000000 ==> Testing loss: 1.059321    Testing error rate: 29.000000
50.000000/100.000000 ==> Testing loss: 1.220766    Testing error rate: 28.000000
==> Total testing loss: 99.185659    Total testing error rate: 24.850000
==> Saving checkpoint..
==> Set learning rate: 0.001000
==> Training Epoch: 55
0.000000/1000.000000 ==> Training loss: 0.082388    Training error rate: 2.000000
50.000000/1000.000000 ==> Training loss: 0.033858    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.057892    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.078163    Training error rate: 2.000000
200.000000/1000.000000 ==> Training loss: 0.026420    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.034912    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.072076    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.023026    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.145675    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.071907    Training error rate: 2.000000
500.000000/1000.000000 ==> Training loss: 0.096669    Training error rate: 2.000000
550.000000/1000.000000 ==> Training loss: 0.104702    Training error rate: 4.000000
600.000000/1000.000000 ==> Training loss: 0.066871    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.122801    Training error rate: 4.000000
700.000000/1000.000000 ==> Training loss: 0.045834    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.144172    Training error rate: 4.000000
800.000000/1000.000000 ==> Training loss: 0.102536    Training error rate: 4.000000
850.000000/1000.000000 ==> Training loss: 0.035672    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.062928    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.049997    Training error rate: 0.000000
==> Total training loss: 57.784344    Total training error rate: 1.224000
==> Testing Epoch: 55
0.000000/100.000000 ==> Testing loss: 1.033215    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.245975    Testing error rate: 29.000000
==> Total testing loss: 99.406391    Total testing error rate: 24.790000
==> Saving checkpoint..
==> Set learning rate: 0.001000
==> Training Epoch: 56
0.000000/1000.000000 ==> Training loss: 0.018015    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.120274    Training error rate: 6.000000
100.000000/1000.000000 ==> Training loss: 0.025812    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.047478    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.057772    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.052912    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.074759    Training error rate: 4.000000
350.000000/1000.000000 ==> Training loss: 0.037253    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.050346    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.027619    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.021516    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.059190    Training error rate: 4.000000
600.000000/1000.000000 ==> Training loss: 0.045843    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.053882    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.043031    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.124422    Training error rate: 6.000000
800.000000/1000.000000 ==> Training loss: 0.041141    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.111315    Training error rate: 4.000000
900.000000/1000.000000 ==> Training loss: 0.080048    Training error rate: 2.000000
950.000000/1000.000000 ==> Training loss: 0.029219    Training error rate: 0.000000
==> Total training loss: 51.361022    Total training error rate: 0.970000
==> Testing Epoch: 56
0.000000/100.000000 ==> Testing loss: 0.999240    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.301250    Testing error rate: 31.000000
==> Total testing loss: 99.436867    Total testing error rate: 24.610000
==> Saving checkpoint..
==> Set learning rate: 0.001000
==> Training Epoch: 57
0.000000/1000.000000 ==> Training loss: 0.035898    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.071994    Training error rate: 2.000000
100.000000/1000.000000 ==> Training loss: 0.052446    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.071721    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.042238    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.015658    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.096474    Training error rate: 4.000000
350.000000/1000.000000 ==> Training loss: 0.051068    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.059660    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.015459    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.084207    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.038893    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.034346    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.044508    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.033067    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.039174    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.059547    Training error rate: 2.000000
850.000000/1000.000000 ==> Training loss: 0.016634    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.023893    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.022475    Training error rate: 0.000000
==> Total training loss: 47.603975    Total training error rate: 0.884000
==> Testing Epoch: 57
0.000000/100.000000 ==> Testing loss: 1.023269    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.285620    Testing error rate: 27.000000
==> Total testing loss: 100.118764    Total testing error rate: 24.420000
==> Saving checkpoint..
==> Set learning rate: 0.001000
==> Training Epoch: 58
0.000000/1000.000000 ==> Training loss: 0.099020    Training error rate: 2.000000
50.000000/1000.000000 ==> Training loss: 0.029208    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.019857    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.056499    Training error rate: 2.000000
200.000000/1000.000000 ==> Training loss: 0.086813    Training error rate: 2.000000
250.000000/1000.000000 ==> Training loss: 0.053374    Training error rate: 2.000000
300.000000/1000.000000 ==> Training loss: 0.043966    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.058640    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.030514    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.057960    Training error rate: 2.000000
500.000000/1000.000000 ==> Training loss: 0.055531    Training error rate: 2.000000
550.000000/1000.000000 ==> Training loss: 0.040201    Training error rate: 2.000000
600.000000/1000.000000 ==> Training loss: 0.028212    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.064271    Training error rate: 4.000000
700.000000/1000.000000 ==> Training loss: 0.038837    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.023522    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.026382    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.024934    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.039729    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.048313    Training error rate: 2.000000
==> Total training loss: 44.279053    Total training error rate: 0.820000
==> Testing Epoch: 58
0.000000/100.000000 ==> Testing loss: 1.024353    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.237293    Testing error rate: 31.000000
==> Total testing loss: 100.045501    Total testing error rate: 24.160000
==> Saving checkpoint..
==> Set learning rate: 0.001000
==> Training Epoch: 59
0.000000/1000.000000 ==> Training loss: 0.028003    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.057323    Training error rate: 2.000000
100.000000/1000.000000 ==> Training loss: 0.030143    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.055601    Training error rate: 2.000000
200.000000/1000.000000 ==> Training loss: 0.039076    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.030770    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.024784    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.029525    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.072969    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.055427    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.067935    Training error rate: 2.000000
550.000000/1000.000000 ==> Training loss: 0.023962    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.022495    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.023969    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.014236    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.027301    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.025981    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.021504    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.030073    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.021109    Training error rate: 0.000000
==> Total training loss: 41.301489    Total training error rate: 0.702000
==> Testing Epoch: 59
0.000000/100.000000 ==> Testing loss: 0.984160    Testing error rate: 23.000000
50.000000/100.000000 ==> Testing loss: 1.279824    Testing error rate: 31.000000
==> Total testing loss: 100.379681    Total testing error rate: 24.230000
==> Set learning rate: 0.001000
==> Training Epoch: 60
0.000000/1000.000000 ==> Training loss: 0.040817    Training error rate: 2.000000
50.000000/1000.000000 ==> Training loss: 0.037489    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.072448    Training error rate: 4.000000
150.000000/1000.000000 ==> Training loss: 0.062173    Training error rate: 4.000000
200.000000/1000.000000 ==> Training loss: 0.026770    Training error rate: 2.000000
250.000000/1000.000000 ==> Training loss: 0.053958    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.036005    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.081920    Training error rate: 4.000000
400.000000/1000.000000 ==> Training loss: 0.034073    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.017499    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.022242    Training error rate: 2.000000
550.000000/1000.000000 ==> Training loss: 0.034639    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.032037    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.024093    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.038291    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.031144    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.017803    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.075995    Training error rate: 2.000000
900.000000/1000.000000 ==> Training loss: 0.070863    Training error rate: 2.000000
950.000000/1000.000000 ==> Training loss: 0.025270    Training error rate: 0.000000
==> Total training loss: 37.647444    Total training error rate: 0.638000
==> Testing Epoch: 60
0.000000/100.000000 ==> Testing loss: 1.008017    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.240252    Testing error rate: 27.000000
==> Total testing loss: 100.597337    Total testing error rate: 24.470000
==> Set learning rate: 0.001000
==> Training Epoch: 61
0.000000/1000.000000 ==> Training loss: 0.031985    Training error rate: 2.000000
50.000000/1000.000000 ==> Training loss: 0.078233    Training error rate: 2.000000
100.000000/1000.000000 ==> Training loss: 0.057365    Training error rate: 2.000000
150.000000/1000.000000 ==> Training loss: 0.011875    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.014924    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.027472    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.054118    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.049874    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.014666    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.025673    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.032153    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.031149    Training error rate: 2.000000
600.000000/1000.000000 ==> Training loss: 0.035511    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.023588    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.024953    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.011964    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.022278    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.071762    Training error rate: 2.000000
900.000000/1000.000000 ==> Training loss: 0.020871    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.124526    Training error rate: 2.000000
==> Total training loss: 35.150144    Total training error rate: 0.554000
==> Testing Epoch: 61
0.000000/100.000000 ==> Testing loss: 0.979228    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.264777    Testing error rate: 26.000000
==> Total testing loss: 100.754848    Total testing error rate: 24.180000
==> Set learning rate: 0.001000
==> Training Epoch: 62
0.000000/1000.000000 ==> Training loss: 0.102598    Training error rate: 2.000000
50.000000/1000.000000 ==> Training loss: 0.053360    Training error rate: 2.000000
100.000000/1000.000000 ==> Training loss: 0.026148    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.029381    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.013542    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.045666    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.048007    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.034960    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.039205    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.056842    Training error rate: 2.000000
500.000000/1000.000000 ==> Training loss: 0.011331    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.154099    Training error rate: 4.000000
600.000000/1000.000000 ==> Training loss: 0.035916    Training error rate: 2.000000
650.000000/1000.000000 ==> Training loss: 0.022726    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.088255    Training error rate: 4.000000
750.000000/1000.000000 ==> Training loss: 0.042975    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.070060    Training error rate: 2.000000
850.000000/1000.000000 ==> Training loss: 0.032458    Training error rate: 2.000000
900.000000/1000.000000 ==> Training loss: 0.058515    Training error rate: 2.000000
950.000000/1000.000000 ==> Training loss: 0.034220    Training error rate: 2.000000
==> Total training loss: 33.270623    Total training error rate: 0.508000
==> Testing Epoch: 62
0.000000/100.000000 ==> Testing loss: 1.001143    Testing error rate: 24.000000
50.000000/100.000000 ==> Testing loss: 1.196291    Testing error rate: 26.000000
==> Total testing loss: 100.586960    Total testing error rate: 24.430000
==> Set learning rate: 0.001000
==> Training Epoch: 63
0.000000/1000.000000 ==> Training loss: 0.035367    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.054323    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.030386    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.012624    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.019226    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.029179    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.066098    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.020661    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.068488    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.020304    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.061496    Training error rate: 2.000000
550.000000/1000.000000 ==> Training loss: 0.085331    Training error rate: 2.000000
600.000000/1000.000000 ==> Training loss: 0.060472    Training error rate: 2.000000
650.000000/1000.000000 ==> Training loss: 0.028548    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.014342    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.026402    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.022260    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.027520    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.064316    Training error rate: 2.000000
950.000000/1000.000000 ==> Training loss: 0.048884    Training error rate: 2.000000
==> Total training loss: 30.827323    Total training error rate: 0.458000
==> Testing Epoch: 63
0.000000/100.000000 ==> Testing loss: 1.021163    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.309958    Testing error rate: 26.000000
==> Total testing loss: 101.349573    Total testing error rate: 24.590000
==> Set learning rate: 0.001000
==> Training Epoch: 64
0.000000/1000.000000 ==> Training loss: 0.020635    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.040044    Training error rate: 2.000000
100.000000/1000.000000 ==> Training loss: 0.092804    Training error rate: 4.000000
150.000000/1000.000000 ==> Training loss: 0.035976    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.052060    Training error rate: 2.000000
250.000000/1000.000000 ==> Training loss: 0.032383    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.020126    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.014871    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.011053    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.036061    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.045157    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.031390    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.021079    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.011654    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.031783    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.043530    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.012727    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.027471    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.021392    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.012958    Training error rate: 0.000000
==> Total training loss: 30.019670    Total training error rate: 0.472000
==> Testing Epoch: 64
0.000000/100.000000 ==> Testing loss: 1.036818    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.283989    Testing error rate: 27.000000
==> Total testing loss: 101.251683    Total testing error rate: 24.260000
==> Set learning rate: 0.001000
==> Training Epoch: 65
0.000000/1000.000000 ==> Training loss: 0.026292    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.035412    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.027350    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.053769    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.018008    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.031587    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.021208    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.018127    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.039177    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.098424    Training error rate: 4.000000
500.000000/1000.000000 ==> Training loss: 0.073588    Training error rate: 2.000000
550.000000/1000.000000 ==> Training loss: 0.039204    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.027221    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.077293    Training error rate: 4.000000
700.000000/1000.000000 ==> Training loss: 0.019707    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.044770    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.039826    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.014604    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.025608    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.065210    Training error rate: 2.000000
==> Total training loss: 28.353851    Total training error rate: 0.434000
==> Testing Epoch: 65
0.000000/100.000000 ==> Testing loss: 1.032904    Testing error rate: 25.000000
50.000000/100.000000 ==> Testing loss: 1.281205    Testing error rate: 26.000000
==> Total testing loss: 101.969552    Total testing error rate: 24.170000
==> Set learning rate: 0.001000
==> Training Epoch: 66
0.000000/1000.000000 ==> Training loss: 0.027836    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.018190    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.026294    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.021607    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.009109    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.022373    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.060135    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.029304    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.009487    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.028909    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.017221    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.031388    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.007478    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.012473    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.011913    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.018945    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.043143    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.009810    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.021416    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.017674    Training error rate: 0.000000
==> Total training loss: 26.808715    Total training error rate: 0.346000
==> Testing Epoch: 66
0.000000/100.000000 ==> Testing loss: 1.062128    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.261651    Testing error rate: 26.000000
==> Total testing loss: 101.351854    Total testing error rate: 24.340000
==> Set learning rate: 0.001000
==> Training Epoch: 67
0.000000/1000.000000 ==> Training loss: 0.006164    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.013007    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.030190    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.032936    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.012115    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.008391    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.033097    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.009387    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.021622    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.010607    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.020651    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.033947    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.018674    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.077122    Training error rate: 4.000000
700.000000/1000.000000 ==> Training loss: 0.062997    Training error rate: 4.000000
750.000000/1000.000000 ==> Training loss: 0.011455    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.012817    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.019569    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.047178    Training error rate: 2.000000
950.000000/1000.000000 ==> Training loss: 0.031769    Training error rate: 0.000000
==> Total training loss: 25.222304    Total training error rate: 0.330000
==> Testing Epoch: 67
0.000000/100.000000 ==> Testing loss: 1.040892    Testing error rate: 28.000000
50.000000/100.000000 ==> Testing loss: 1.238227    Testing error rate: 26.000000
==> Total testing loss: 101.575508    Total testing error rate: 24.440000
==> Set learning rate: 0.001000
==> Training Epoch: 68
0.000000/1000.000000 ==> Training loss: 0.020292    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.014641    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.029842    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.022160    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.010571    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.012379    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.017542    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.020803    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.035616    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.016005    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.058604    Training error rate: 2.000000
550.000000/1000.000000 ==> Training loss: 0.031128    Training error rate: 2.000000
600.000000/1000.000000 ==> Training loss: 0.016195    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.011243    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.018783    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.027543    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.044256    Training error rate: 2.000000
850.000000/1000.000000 ==> Training loss: 0.037247    Training error rate: 2.000000
900.000000/1000.000000 ==> Training loss: 0.008993    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.016886    Training error rate: 0.000000
==> Total training loss: 24.323608    Total training error rate: 0.312000
==> Testing Epoch: 68
0.000000/100.000000 ==> Testing loss: 1.102193    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.248901    Testing error rate: 26.000000
==> Total testing loss: 102.083447    Total testing error rate: 24.420000
==> Set learning rate: 0.001000
==> Training Epoch: 69
0.000000/1000.000000 ==> Training loss: 0.019585    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.049037    Training error rate: 2.000000
100.000000/1000.000000 ==> Training loss: 0.022800    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.014082    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.020089    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.019034    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.021229    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.046802    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.064765    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.017105    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.033843    Training error rate: 2.000000
550.000000/1000.000000 ==> Training loss: 0.011761    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.022585    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.070979    Training error rate: 2.000000
700.000000/1000.000000 ==> Training loss: 0.024806    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.014471    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.007970    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.010672    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.045205    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.006760    Training error rate: 0.000000
==> Total training loss: 24.779610    Total training error rate: 0.332000
==> Testing Epoch: 69
0.000000/100.000000 ==> Testing loss: 1.078818    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.291101    Testing error rate: 28.000000
==> Total testing loss: 102.684116    Total testing error rate: 24.270000
==> Set learning rate: 0.001000
==> Training Epoch: 70
0.000000/1000.000000 ==> Training loss: 0.012751    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.011508    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.031278    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.006210    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.016263    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.021544    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.028078    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.024368    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.011340    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.011182    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.009067    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.063393    Training error rate: 2.000000
600.000000/1000.000000 ==> Training loss: 0.018650    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.013467    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.032023    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.061514    Training error rate: 2.000000
800.000000/1000.000000 ==> Training loss: 0.017040    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.010468    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.027271    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.007806    Training error rate: 0.000000
==> Total training loss: 23.551706    Total training error rate: 0.298000
==> Testing Epoch: 70
0.000000/100.000000 ==> Testing loss: 1.079149    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.288799    Testing error rate: 28.000000
==> Total testing loss: 102.590831    Total testing error rate: 24.250000
==> Set learning rate: 0.001000
==> Training Epoch: 71
0.000000/1000.000000 ==> Training loss: 0.020570    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.017303    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.016580    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.010063    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.018872    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.030243    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.014626    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.021878    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.012581    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.026257    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.017019    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.018063    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.024124    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.028420    Training error rate: 2.000000
700.000000/1000.000000 ==> Training loss: 0.039393    Training error rate: 2.000000
750.000000/1000.000000 ==> Training loss: 0.023435    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.006801    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.015130    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.009622    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.028225    Training error rate: 0.000000
==> Total training loss: 22.723449    Total training error rate: 0.304000
==> Testing Epoch: 71
0.000000/100.000000 ==> Testing loss: 1.057729    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.293222    Testing error rate: 26.000000
==> Total testing loss: 101.936339    Total testing error rate: 24.330000
==> Set learning rate: 0.001000
==> Training Epoch: 72
0.000000/1000.000000 ==> Training loss: 0.008060    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.010679    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.014952    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.019790    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.084274    Training error rate: 2.000000
250.000000/1000.000000 ==> Training loss: 0.036622    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.019018    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.054336    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.005483    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.030979    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.019847    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.049076    Training error rate: 2.000000
600.000000/1000.000000 ==> Training loss: 0.016721    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.039944    Training error rate: 2.000000
700.000000/1000.000000 ==> Training loss: 0.032681    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.008582    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.008702    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.007928    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.015431    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.028222    Training error rate: 0.000000
==> Total training loss: 21.520120    Total training error rate: 0.240000
==> Testing Epoch: 72
0.000000/100.000000 ==> Testing loss: 1.098386    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.329822    Testing error rate: 27.000000
==> Total testing loss: 101.984923    Total testing error rate: 24.260000
==> Set learning rate: 0.001000
==> Training Epoch: 73
0.000000/1000.000000 ==> Training loss: 0.026265    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.007853    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.020701    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.012106    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.017165    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.008778    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.014695    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.067934    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.009956    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.013911    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.008886    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.025724    Training error rate: 2.000000
600.000000/1000.000000 ==> Training loss: 0.036866    Training error rate: 2.000000
650.000000/1000.000000 ==> Training loss: 0.043635    Training error rate: 2.000000
700.000000/1000.000000 ==> Training loss: 0.018857    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.005594    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.028278    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.009686    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.014504    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.013447    Training error rate: 0.000000
==> Total training loss: 20.073609    Total training error rate: 0.204000
==> Testing Epoch: 73
0.000000/100.000000 ==> Testing loss: 1.095799    Testing error rate: 28.000000
50.000000/100.000000 ==> Testing loss: 1.349471    Testing error rate: 28.000000
==> Total testing loss: 102.165120    Total testing error rate: 24.370000
==> Set learning rate: 0.001000
==> Training Epoch: 74
0.000000/1000.000000 ==> Training loss: 0.009027    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.005517    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.024696    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.072687    Training error rate: 2.000000
200.000000/1000.000000 ==> Training loss: 0.029569    Training error rate: 2.000000
250.000000/1000.000000 ==> Training loss: 0.016912    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.006857    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.013086    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.006705    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.021688    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.036523    Training error rate: 2.000000
550.000000/1000.000000 ==> Training loss: 0.023403    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.016209    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.016163    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.018797    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.011287    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.012857    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.038495    Training error rate: 2.000000
900.000000/1000.000000 ==> Training loss: 0.009849    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.024399    Training error rate: 0.000000
==> Total training loss: 19.892484    Total training error rate: 0.232000
==> Testing Epoch: 74
0.000000/100.000000 ==> Testing loss: 1.142091    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.367917    Testing error rate: 27.000000
==> Total testing loss: 103.073544    Total testing error rate: 24.200000
==> Set learning rate: 0.001000
==> Training Epoch: 75
0.000000/1000.000000 ==> Training loss: 0.009938    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.024357    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.013277    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.011652    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.022755    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.014036    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.027894    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.021198    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.014131    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.017257    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.025311    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.011055    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.023017    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.022242    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.016851    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.006685    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.017907    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.038043    Training error rate: 2.000000
900.000000/1000.000000 ==> Training loss: 0.007794    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.005230    Training error rate: 0.000000
==> Total training loss: 19.529750    Total training error rate: 0.220000
==> Testing Epoch: 75
0.000000/100.000000 ==> Testing loss: 1.123411    Testing error rate: 25.000000
50.000000/100.000000 ==> Testing loss: 1.326125    Testing error rate: 27.000000
==> Total testing loss: 102.231481    Total testing error rate: 24.160000
==> Set learning rate: 0.001000
==> Training Epoch: 76
==> Init variables..
==> Init seed..
==> Download data..
Files already downloaded and verified
==> Calculate mean and std..
==> Prepare training transform..
==> Prepare testing transform..
==> Init dataloader..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
==> Resuming from checkpoint..
==> Set learning rate: 0.001000
==> Training Epoch: 58
0.000000/1000.000000 ==> Training loss: 0.035116    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.037366    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.033749    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.035981    Training error rate: 2.000000
200.000000/1000.000000 ==> Training loss: 0.036261    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.032398    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.059550    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.037528    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.075658    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.023867    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.016804    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.101726    Training error rate: 2.000000
600.000000/1000.000000 ==> Training loss: 0.095247    Training error rate: 2.000000
650.000000/1000.000000 ==> Training loss: 0.014185    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.023886    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.016695    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.018895    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.091005    Training error rate: 4.000000
900.000000/1000.000000 ==> Training loss: 0.034684    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.040138    Training error rate: 0.000000
==> Total training loss: 39.856876    Total training error rate: 0.682000
==> Testing Epoch: 58
0.000000/100.000000 ==> Testing loss: 0.995430    Testing error rate: 29.000000
50.000000/100.000000 ==> Testing loss: 1.225943    Testing error rate: 29.000000
==> Total testing loss: 100.546327    Total testing error rate: 24.430000
==> Set learning rate: 0.001000
==> Training Epoch: 59
0.000000/1000.000000 ==> Training loss: 0.042241    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.020107    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.030082    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.035345    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.038947    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.055224    Training error rate: 2.000000
300.000000/1000.000000 ==> Training loss: 0.023783    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.021100    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.052833    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.035990    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.037552    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.017936    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.023890    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.087635    Training error rate: 4.000000
700.000000/1000.000000 ==> Training loss: 0.024067    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.035569    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.022737    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.027545    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.031128    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.037240    Training error rate: 2.000000
==> Total training loss: 37.940150    Total training error rate: 0.664000
==> Testing Epoch: 59
0.000000/100.000000 ==> Testing loss: 1.022733    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.257872    Testing error rate: 31.000000
==> Total testing loss: 100.344895    Total testing error rate: 24.290000
==> Set learning rate: 0.001000
==> Training Epoch: 60
0.000000/1000.000000 ==> Training loss: 0.041014    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.037717    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.012810    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.022167    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.044647    Training error rate: 2.000000
250.000000/1000.000000 ==> Training loss: 0.038616    Training error rate: 2.000000
300.000000/1000.000000 ==> Training loss: 0.021687    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.029914    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.063651    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.013298    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.055635    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.015844    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.037875    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.086729    Training error rate: 4.000000
700.000000/1000.000000 ==> Training loss: 0.017933    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.057354    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.034245    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.018064    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.050606    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.056296    Training error rate: 0.000000
==> Total training loss: 36.280233    Total training error rate: 0.606000
==> Testing Epoch: 60
0.000000/100.000000 ==> Testing loss: 1.022688    Testing error rate: 25.000000
50.000000/100.000000 ==> Testing loss: 1.298247    Testing error rate: 31.000000
==> Total testing loss: 101.445128    Total testing error rate: 24.780000
==> Set learning rate: 0.001000
==> Training Epoch: 61
0.000000/1000.000000 ==> Training loss: 0.037407    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.035394    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.038166    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.020893    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.127909    Training error rate: 6.000000
250.000000/1000.000000 ==> Training loss: 0.024936    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.013366    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.021485    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.021476    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.042534    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.106388    Training error rate: 4.000000
550.000000/1000.000000 ==> Training loss: 0.008905    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.011573    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.022273    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.013992    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.035099    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.016759    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.034825    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.013468    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.026158    Training error rate: 0.000000
==> Total training loss: 34.090949    Total training error rate: 0.546000
==> Testing Epoch: 61
0.000000/100.000000 ==> Testing loss: 1.032136    Testing error rate: 25.000000
50.000000/100.000000 ==> Testing loss: 1.276911    Testing error rate: 28.000000
==> Total testing loss: 100.445659    Total testing error rate: 24.500000
==> Set learning rate: 0.001000
==> Training Epoch: 62
0.000000/1000.000000 ==> Training loss: 0.035525    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.032401    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.017925    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.027887    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.028267    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.046506    Training error rate: 2.000000
300.000000/1000.000000 ==> Training loss: 0.100282    Training error rate: 6.000000
350.000000/1000.000000 ==> Training loss: 0.060956    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.040240    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.017635    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.008378    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.014716    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.095239    Training error rate: 2.000000
650.000000/1000.000000 ==> Training loss: 0.027822    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.031633    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.032192    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.033792    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.011509    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.032024    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.025323    Training error rate: 0.000000
==> Total training loss: 32.242569    Total training error rate: 0.534000
==> Testing Epoch: 62
0.000000/100.000000 ==> Testing loss: 1.044562    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.291924    Testing error rate: 27.000000
==> Total testing loss: 101.678734    Total testing error rate: 24.460000
==> Set learning rate: 0.001000
==> Training Epoch: 63
0.000000/1000.000000 ==> Training loss: 0.061424    Training error rate: 2.000000
50.000000/1000.000000 ==> Training loss: 0.026479    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.032378    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.069390    Training error rate: 4.000000
200.000000/1000.000000 ==> Training loss: 0.031888    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.009509    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.019819    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.046640    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.039424    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.014316    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.025337    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.022395    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.031251    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.035917    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.098221    Training error rate: 6.000000
750.000000/1000.000000 ==> Training loss: 0.008787    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.073321    Training error rate: 2.000000
850.000000/1000.000000 ==> Training loss: 0.018771    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.052403    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.012545    Training error rate: 0.000000
==> Total training loss: 29.255290    Total training error rate: 0.420000
==> Testing Epoch: 63
0.000000/100.000000 ==> Testing loss: 1.042686    Testing error rate: 25.000000
50.000000/100.000000 ==> Testing loss: 1.281157    Testing error rate: 28.000000
==> Total testing loss: 101.627624    Total testing error rate: 24.330000
==> Set learning rate: 0.001000
==> Training Epoch: 64
0.000000/1000.000000 ==> Training loss: 0.020800    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.015131    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.022680    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.024816    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.025085    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.013455    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.045634    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.019195    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.037275    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.025545    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.058917    Training error rate: 2.000000
550.000000/1000.000000 ==> Training loss: 0.045188    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.015963    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.059533    Training error rate: 2.000000
700.000000/1000.000000 ==> Training loss: 0.066597    Training error rate: 2.000000
750.000000/1000.000000 ==> Training loss: 0.057825    Training error rate: 2.000000
800.000000/1000.000000 ==> Training loss: 0.012459    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.012583    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.039619    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.044184    Training error rate: 0.000000
==> Total training loss: 28.677893    Total training error rate: 0.446000
==> Testing Epoch: 64
0.000000/100.000000 ==> Testing loss: 1.025816    Testing error rate: 29.000000
50.000000/100.000000 ==> Testing loss: 1.303696    Testing error rate: 30.000000
==> Total testing loss: 101.208951    Total testing error rate: 24.650000
==> Set learning rate: 0.001000
==> Training Epoch: 65
0.000000/1000.000000 ==> Training loss: 0.014019    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.021396    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.029368    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.061210    Training error rate: 2.000000
200.000000/1000.000000 ==> Training loss: 0.065006    Training error rate: 2.000000
250.000000/1000.000000 ==> Training loss: 0.016761    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.020300    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.048555    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.068537    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.030320    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.024883    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.032938    Training error rate: 2.000000
600.000000/1000.000000 ==> Training loss: 0.032434    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.020575    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.054508    Training error rate: 2.000000
750.000000/1000.000000 ==> Training loss: 0.016044    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.086938    Training error rate: 2.000000
850.000000/1000.000000 ==> Training loss: 0.021459    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.032736    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.019524    Training error rate: 0.000000
==> Total training loss: 27.144946    Total training error rate: 0.380000
==> Testing Epoch: 65
0.000000/100.000000 ==> Testing loss: 1.019945    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.298073    Testing error rate: 29.000000
==> Total testing loss: 102.509675    Total testing error rate: 24.520000
==> Set learning rate: 0.001000
==> Training Epoch: 66
0.000000/1000.000000 ==> Training loss: 0.030667    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.035656    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.006569    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.022983    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.009780    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.021394    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.008171    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.031454    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.036445    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.010606    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.012043    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.010368    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.011289    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.028497    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.070744    Training error rate: 4.000000
750.000000/1000.000000 ==> Training loss: 0.009935    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.018706    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.024438    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.078629    Training error rate: 2.000000
950.000000/1000.000000 ==> Training loss: 0.005288    Training error rate: 0.000000
==> Total training loss: 26.058091    Total training error rate: 0.402000
==> Testing Epoch: 66
0.000000/100.000000 ==> Testing loss: 0.987577    Testing error rate: 24.000000
50.000000/100.000000 ==> Testing loss: 1.317406    Testing error rate: 28.000000
==> Total testing loss: 101.805445    Total testing error rate: 24.370000
==> Set learning rate: 0.001000
==> Training Epoch: 67
0.000000/1000.000000 ==> Training loss: 0.035861    Training error rate: 2.000000
50.000000/1000.000000 ==> Training loss: 0.020346    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.011638    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.012668    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.024476    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.031421    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.024695    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.017927    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.008907    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.074717    Training error rate: 2.000000
500.000000/1000.000000 ==> Training loss: 0.050610    Training error rate: 2.000000
550.000000/1000.000000 ==> Training loss: 0.026239    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.026433    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.009441    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.014780    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.028109    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.013427    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.027560    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.011164    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.018099    Training error rate: 0.000000
==> Total training loss: 24.491852    Total training error rate: 0.324000
==> Testing Epoch: 67
0.000000/100.000000 ==> Testing loss: 1.045354    Testing error rate: 25.000000
50.000000/100.000000 ==> Testing loss: 1.280666    Testing error rate: 28.000000
==> Total testing loss: 101.764395    Total testing error rate: 24.470000
==> Set learning rate: 0.001000
==> Training Epoch: 68
0.000000/1000.000000 ==> Training loss: 0.011360    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.020330    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.014473    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.022206    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.021255    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.014942    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.046626    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.014004    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.024609    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.013303    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.022998    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.058046    Training error rate: 2.000000
600.000000/1000.000000 ==> Training loss: 0.020604    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.016744    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.006119    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.026847    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.018976    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.022988    Training error rate: 2.000000
900.000000/1000.000000 ==> Training loss: 0.024673    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.009216    Training error rate: 0.000000
==> Total training loss: 23.668357    Total training error rate: 0.288000
==> Testing Epoch: 68
0.000000/100.000000 ==> Testing loss: 1.010744    Testing error rate: 28.000000
50.000000/100.000000 ==> Testing loss: 1.245921    Testing error rate: 26.000000
==> Total testing loss: 101.462976    Total testing error rate: 24.000000
==> Saving checkpoint..
==> Set learning rate: 0.001000
==> Training Epoch: 69
0.000000/1000.000000 ==> Training loss: 0.042534    Training error rate: 2.000000
50.000000/1000.000000 ==> Training loss: 0.018455    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.052860    Training error rate: 2.000000
150.000000/1000.000000 ==> Training loss: 0.014098    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.048304    Training error rate: 2.000000
250.000000/1000.000000 ==> Training loss: 0.019974    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.019827    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.010955    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.050564    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.017457    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.032265    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.036368    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.016879    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.005524    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.021218    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.013549    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.012328    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.027365    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.024384    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.023958    Training error rate: 0.000000
==> Total training loss: 23.155768    Total training error rate: 0.306000
==> Testing Epoch: 69
0.000000/100.000000 ==> Testing loss: 1.058121    Testing error rate: 25.000000
50.000000/100.000000 ==> Testing loss: 1.272055    Testing error rate: 27.000000
==> Total testing loss: 102.010801    Total testing error rate: 24.220000
==> Set learning rate: 0.001000
==> Training Epoch: 70
0.000000/1000.000000 ==> Training loss: 0.016783    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.012437    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.017553    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.026974    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.008650    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.016146    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.023484    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.013724    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.009590    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.046728    Training error rate: 2.000000
500.000000/1000.000000 ==> Training loss: 0.012056    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.025650    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.013298    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.016016    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.009948    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.016629    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.018750    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.052889    Training error rate: 2.000000
900.000000/1000.000000 ==> Training loss: 0.072428    Training error rate: 2.000000
950.000000/1000.000000 ==> Training loss: 0.027428    Training error rate: 0.000000
==> Total training loss: 22.250748    Total training error rate: 0.298000
==> Testing Epoch: 70
0.000000/100.000000 ==> Testing loss: 1.097992    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.275512    Testing error rate: 27.000000
==> Total testing loss: 102.421559    Total testing error rate: 24.260000
==> Set learning rate: 0.001000
==> Training Epoch: 71
0.000000/1000.000000 ==> Training loss: 0.011744    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.028014    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.019320    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.007587    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.048539    Training error rate: 2.000000
250.000000/1000.000000 ==> Training loss: 0.007410    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.035664    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.015519    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.018609    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.014978    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.028458    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.017290    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.013726    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.011365    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.009489    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.012076    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.079949    Training error rate: 2.000000
850.000000/1000.000000 ==> Training loss: 0.024862    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.015143    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.011671    Training error rate: 0.000000
==> Total training loss: 22.028016    Total training error rate: 0.276000
==> Testing Epoch: 71
0.000000/100.000000 ==> Testing loss: 1.090538    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.307234    Testing error rate: 26.000000
==> Total testing loss: 102.137939    Total testing error rate: 24.130000
==> Set learning rate: 0.001000
==> Training Epoch: 72
0.000000/1000.000000 ==> Training loss: 0.021982    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.031704    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.020214    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.012373    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.016249    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.010316    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.021346    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.032127    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.034005    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.008235    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.008528    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.014143    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.007456    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.026038    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.022573    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.013868    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.014770    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.017039    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.038713    Training error rate: 2.000000
950.000000/1000.000000 ==> Training loss: 0.032487    Training error rate: 0.000000
==> Total training loss: 20.752194    Total training error rate: 0.262000
==> Testing Epoch: 72
0.000000/100.000000 ==> Testing loss: 1.084502    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.339077    Testing error rate: 27.000000
==> Total testing loss: 102.571998    Total testing error rate: 24.350000
==> Set learning rate: 0.001000
==> Training Epoch: 73
0.000000/1000.000000 ==> Training loss: 0.026493    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.005879    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.018350    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.055011    Training error rate: 2.000000
200.000000/1000.000000 ==> Training loss: 0.009013    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.017213    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.021929    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.015092    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.011971    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.017978    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.009911    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.019322    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.010866    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.008408    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.016829    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.022481    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.017648    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.044126    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.013702    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.010094    Training error rate: 0.000000
==> Total training loss: 20.207775    Total training error rate: 0.258000
==> Testing Epoch: 73
0.000000/100.000000 ==> Testing loss: 1.114974    Testing error rate: 23.000000
50.000000/100.000000 ==> Testing loss: 1.370469    Testing error rate: 28.000000
==> Total testing loss: 102.118938    Total testing error rate: 24.040000
==> Set learning rate: 0.001000
==> Training Epoch: 74
0.000000/1000.000000 ==> Training loss: 0.006096    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.026095    Training error rate: 2.000000
100.000000/1000.000000 ==> Training loss: 0.025821    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.017491    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.012310    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.013736    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.013781    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.030297    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.008712    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.019023    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.015272    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.008856    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.022971    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.032688    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.025407    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.022692    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.043757    Training error rate: 2.000000
850.000000/1000.000000 ==> Training loss: 0.029624    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.005662    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.018276    Training error rate: 0.000000
==> Total training loss: 20.386722    Total training error rate: 0.262000
==> Testing Epoch: 74
0.000000/100.000000 ==> Testing loss: 1.112304    Testing error rate: 28.000000
50.000000/100.000000 ==> Testing loss: 1.287231    Testing error rate: 27.000000
==> Total testing loss: 101.988598    Total testing error rate: 24.310000
==> Set learning rate: 0.001000
==> Training Epoch: 75
0.000000/1000.000000 ==> Training loss: 0.040803    Training error rate: 2.000000
50.000000/1000.000000 ==> Training loss: 0.009984    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.009424    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.009097    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.023098    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.036668    Training error rate: 2.000000
300.000000/1000.000000 ==> Training loss: 0.041253    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.015695    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.015338    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.008735    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.034531    Training error rate: 2.000000
550.000000/1000.000000 ==> Training loss: 0.009388    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.013068    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.009866    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.018464    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.047499    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.037753    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.017697    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.006525    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.030861    Training error rate: 0.000000
==> Total training loss: 19.061599    Total training error rate: 0.214000
==> Testing Epoch: 75
0.000000/100.000000 ==> Testing loss: 1.146623    Testing error rate: 28.000000
50.000000/100.000000 ==> Testing loss: 1.315596    Testing error rate: 28.000000
==> Total testing loss: 103.063669    Total testing error rate: 24.300000
==> Set learning rate: 0.001000
==> Training Epoch: 76
0.000000/1000.000000 ==> Training loss: 0.010998    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.013214    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.027702    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.026802    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.021628    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.006439    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.030848    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.010984    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.005241    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.013452    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.011035    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.022722    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.035014    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.027092    Training error rate: 2.000000
700.000000/1000.000000 ==> Training loss: 0.026865    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.011692    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.020961    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.010452    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.019170    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.017659    Training error rate: 0.000000
==> Total training loss: 17.377527    Total training error rate: 0.160000
==> Testing Epoch: 76
0.000000/100.000000 ==> Testing loss: 1.092803    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.316904    Testing error rate: 26.000000
==> Total testing loss: 102.067814    Total testing error rate: 24.220000
==> Set learning rate: 0.001000
==> Training Epoch: 77
0.000000/1000.000000 ==> Training loss: 0.024589    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.023436    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.027490    Training error rate: 2.000000
150.000000/1000.000000 ==> Training loss: 0.016458    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.014739    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.006067    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.130342    Training error rate: 2.000000
350.000000/1000.000000 ==> Training loss: 0.017787    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.013380    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.009957    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.016687    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.013411    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.018491    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.029205    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.015025    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.018341    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.012850    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.007313    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.008751    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.013810    Training error rate: 0.000000
==> Total training loss: 18.253942    Total training error rate: 0.188000
==> Testing Epoch: 77
0.000000/100.000000 ==> Testing loss: 1.078618    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.327410    Testing error rate: 27.000000
==> Total testing loss: 102.038984    Total testing error rate: 24.110000
==> Set learning rate: 0.001000
==> Training Epoch: 78
0.000000/1000.000000 ==> Training loss: 0.009738    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.010179    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.011393    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.031107    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.012966    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.006988    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.007939    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.033194    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.024669    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.012023    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.010583    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.010764    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.005097    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.027748    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.035277    Training error rate: 2.000000
750.000000/1000.000000 ==> Training loss: 0.006903    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.011880    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.015954    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.011898    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.013819    Training error rate: 0.000000
==> Total training loss: 18.286950    Total training error rate: 0.196000
==> Testing Epoch: 78
0.000000/100.000000 ==> Testing loss: 1.084816    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.271211    Testing error rate: 26.000000
==> Total testing loss: 101.874278    Total testing error rate: 24.300000
==> Set learning rate: 0.001000
==> Training Epoch: 79
0.000000/1000.000000 ==> Training loss: 0.019409    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.032095    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.015464    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.015103    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.009265    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.010187    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.008249    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.007872    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.012346    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.012616    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.011047    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.021438    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.012219    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.017087    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.058118    Training error rate: 2.000000
750.000000/1000.000000 ==> Training loss: 0.012905    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.005958    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.008163    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.033571    Training error rate: 2.000000
950.000000/1000.000000 ==> Training loss: 0.017079    Training error rate: 0.000000
==> Total training loss: 16.514467    Total training error rate: 0.156000
==> Testing Epoch: 79
0.000000/100.000000 ==> Testing loss: 1.131620    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.305632    Testing error rate: 27.000000
==> Total testing loss: 102.316156    Total testing error rate: 24.170000
==> Set learning rate: 0.001000
==> Training Epoch: 80
0.000000/1000.000000 ==> Training loss: 0.011479    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.010137    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.014641    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.013039    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.017378    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.011994    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.021173    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.011916    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.010495    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.019257    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.008009    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.023451    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.050591    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.023309    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.011729    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.011507    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.005764    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.006894    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.021706    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.007973    Training error rate: 0.000000
==> Total training loss: 16.617775    Total training error rate: 0.156000
==> Testing Epoch: 80
0.000000/100.000000 ==> Testing loss: 1.135979    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.292347    Testing error rate: 26.000000
==> Total testing loss: 102.072473    Total testing error rate: 24.120000
==> Set learning rate: 0.001000
==> Training Epoch: 81
0.000000/1000.000000 ==> Training loss: 0.032552    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.012300    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.011623    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.011996    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.011095    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.019401    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.038255    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.008390    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.008583    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.016961    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.009355    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.002807    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.013483    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.016227    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.020254    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.017111    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.019567    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.007431    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.013032    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.009737    Training error rate: 0.000000
==> Total training loss: 16.482881    Total training error rate: 0.152000
==> Testing Epoch: 81
0.000000/100.000000 ==> Testing loss: 1.147146    Testing error rate: 28.000000
50.000000/100.000000 ==> Testing loss: 1.343650    Testing error rate: 28.000000
==> Total testing loss: 103.236560    Total testing error rate: 24.210000
==> Set learning rate: 0.001000
==> Training Epoch: 82
0.000000/1000.000000 ==> Training loss: 0.008253    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.047241    Training error rate: 2.000000
100.000000/1000.000000 ==> Training loss: 0.009258    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.040314    Training error rate: 2.000000
200.000000/1000.000000 ==> Training loss: 0.014595    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.026342    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.011879    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.018568    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.008794    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.007319    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.010165    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.017428    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.010804    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.011453    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.014923    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.011141    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.019986    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.016763    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.033553    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.007455    Training error rate: 0.000000
==> Total training loss: 16.703801    Total training error rate: 0.166000
==> Testing Epoch: 82
0.000000/100.000000 ==> Testing loss: 1.154850    Testing error rate: 24.000000
50.000000/100.000000 ==> Testing loss: 1.312473    Testing error rate: 27.000000
==> Total testing loss: 102.260334    Total testing error rate: 24.210000
==> Set learning rate: 0.001000
==> Training Epoch: 83
0.000000/1000.000000 ==> Training loss: 0.020700    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.018942    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.005938    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.035021    Training error rate: 2.000000
200.000000/1000.000000 ==> Training loss: 0.011382    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.013618    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.008172    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.015139    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.023932    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.015918    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.018631    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.061713    Training error rate: 2.000000
600.000000/1000.000000 ==> Training loss: 0.024635    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.006299    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.018173    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.011990    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.011034    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.018140    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.007339    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.007726    Training error rate: 0.000000
==> Total training loss: 15.910564    Total training error rate: 0.128000
==> Testing Epoch: 83
0.000000/100.000000 ==> Testing loss: 1.119646    Testing error rate: 24.000000
50.000000/100.000000 ==> Testing loss: 1.359262    Testing error rate: 28.000000
==> Total testing loss: 102.054552    Total testing error rate: 24.270000
==> Set learning rate: 0.001000
==> Training Epoch: 84
0.000000/1000.000000 ==> Training loss: 0.023923    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.008036    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.009850    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.013253    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.009843    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.011404    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.016111    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.036947    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.008265    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.022275    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.012231    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.010205    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.009407    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.024636    Training error rate: 2.000000
700.000000/1000.000000 ==> Training loss: 0.026574    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.014383    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.008911    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.018602    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.010141    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.019309    Training error rate: 0.000000
==> Total training loss: 15.885480    Total training error rate: 0.154000
==> Testing Epoch: 84
0.000000/100.000000 ==> Testing loss: 1.144612    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.252631    Testing error rate: 25.000000
==> Total testing loss: 102.058702    Total testing error rate: 24.000000
==> Set learning rate: 0.001000
==> Training Epoch: 85
0.000000/1000.000000 ==> Training loss: 0.014459    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.015581    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.013559    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.009327    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.015646    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.017629    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.029454    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.010685    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.007468    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.006052    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.010191    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.014072    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.012983    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.030025    Training error rate: 2.000000
700.000000/1000.000000 ==> Training loss: 0.022524    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.023460    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.008070    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.009633    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.036913    Training error rate: 2.000000
950.000000/1000.000000 ==> Training loss: 0.015972    Training error rate: 0.000000
==> Total training loss: 15.291119    Total training error rate: 0.152000
==> Testing Epoch: 85
0.000000/100.000000 ==> Testing loss: 1.155050    Testing error rate: 25.000000
50.000000/100.000000 ==> Testing loss: 1.323707    Testing error rate: 28.000000
==> Total testing loss: 102.893100    Total testing error rate: 24.520000
==> Set learning rate: 0.001000
==> Training Epoch: 86
0.000000/1000.000000 ==> Training loss: 0.005139    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.014382    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.005512    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.016240    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.015494    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.008362    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.011387    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.012798    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.016186    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.008201    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.048917    Training error rate: 2.000000
550.000000/1000.000000 ==> Training loss: 0.023486    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.014147    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.008633    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.014589    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.028408    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.012142    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.008240    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.007189    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.031639    Training error rate: 0.000000
==> Total training loss: 15.813077    Total training error rate: 0.144000
==> Testing Epoch: 86
0.000000/100.000000 ==> Testing loss: 1.182142    Testing error rate: 28.000000
50.000000/100.000000 ==> Testing loss: 1.271660    Testing error rate: 27.000000
==> Total testing loss: 102.329945    Total testing error rate: 24.330000
==> Set learning rate: 0.001000
==> Training Epoch: 87
0.000000/1000.000000 ==> Training loss: 0.009475    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.006968    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.020900    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.012499    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.010428    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.012156    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.006887    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.004809    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.019770    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.017206    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.009707    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.005352    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.011180    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.014514    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.009840    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.018422    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.009073    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.025185    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.014288    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.010604    Training error rate: 0.000000
==> Total training loss: 14.679298    Total training error rate: 0.132000
==> Testing Epoch: 87
0.000000/100.000000 ==> Testing loss: 1.186629    Testing error rate: 28.000000
50.000000/100.000000 ==> Testing loss: 1.298491    Testing error rate: 28.000000
==> Total testing loss: 101.970000    Total testing error rate: 23.920000
==> Saving checkpoint..
==> Set learning rate: 0.001000
==> Training Epoch: 88
0.000000/1000.000000 ==> Training loss: 0.018298    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.032527    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.005011    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.009888    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.012940    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.004808    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.015228    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.006427    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.049039    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.014134    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.006402    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.028255    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.005897    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.014919    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.011137    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.024995    Training error rate: 2.000000
800.000000/1000.000000 ==> Training loss: 0.011233    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.008084    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.010484    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.030674    Training error rate: 0.000000
==> Total training loss: 14.793382    Total training error rate: 0.136000
==> Testing Epoch: 88
0.000000/100.000000 ==> Testing loss: 1.193576    Testing error rate: 30.000000
50.000000/100.000000 ==> Testing loss: 1.311569    Testing error rate: 26.000000
==> Total testing loss: 101.806649    Total testing error rate: 24.170000
==> Set learning rate: 0.001000
==> Training Epoch: 89
0.000000/1000.000000 ==> Training loss: 0.009232    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.010511    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.003945    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.010262    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.009297    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.011631    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.020202    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.007518    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.036941    Training error rate: 2.000000
450.000000/1000.000000 ==> Training loss: 0.015098    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.009322    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.026134    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.019012    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.013005    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.053088    Training error rate: 2.000000
750.000000/1000.000000 ==> Training loss: 0.038412    Training error rate: 2.000000
800.000000/1000.000000 ==> Training loss: 0.008946    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.013879    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.007755    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.019287    Training error rate: 0.000000
==> Total training loss: 13.640033    Total training error rate: 0.104000
==> Testing Epoch: 89
0.000000/100.000000 ==> Testing loss: 1.172250    Testing error rate: 29.000000
50.000000/100.000000 ==> Testing loss: 1.344681    Testing error rate: 27.000000
==> Total testing loss: 101.596199    Total testing error rate: 24.120000
==> Set learning rate: 0.001000
==> Training Epoch: 90
0.000000/1000.000000 ==> Training loss: 0.012558    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.013863    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.009304    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.013130    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.020119    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.007222    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.016185    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.037325    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.020339    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.007823    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.009367    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.011090    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.017222    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.013057    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.014050    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.015009    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.017046    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.027382    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.009892    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.006473    Training error rate: 0.000000
==> Total training loss: 13.850481    Total training error rate: 0.102000
==> Testing Epoch: 90
0.000000/100.000000 ==> Testing loss: 1.140454    Testing error rate: 29.000000
50.000000/100.000000 ==> Testing loss: 1.319696    Testing error rate: 26.000000
==> Total testing loss: 101.795668    Total testing error rate: 23.970000
==> Set learning rate: 0.001000
==> Training Epoch: 91
0.000000/1000.000000 ==> Training loss: 0.011444    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.009392    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.011406    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.016066    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.014523    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.013765    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.009598    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.013974    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.015251    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.010479    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.014721    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.012698    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.024706    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.004999    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.005005    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.015102    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.010151    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.010160    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.028009    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.014442    Training error rate: 0.000000
==> Total training loss: 13.679324    Total training error rate: 0.114000
==> Testing Epoch: 91
0.000000/100.000000 ==> Testing loss: 1.143163    Testing error rate: 28.000000
50.000000/100.000000 ==> Testing loss: 1.382767    Testing error rate: 27.000000
==> Total testing loss: 101.727681    Total testing error rate: 24.150000
==> Set learning rate: 0.001000
==> Training Epoch: 92
0.000000/1000.000000 ==> Training loss: 0.024115    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.010200    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.010491    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.048990    Training error rate: 2.000000
200.000000/1000.000000 ==> Training loss: 0.018823    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.013003    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.005326    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.012002    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.034920    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.013803    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.018679    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.052679    Training error rate: 2.000000
600.000000/1000.000000 ==> Training loss: 0.015657    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.008995    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.007287    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.006158    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.006041    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.011746    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.007483    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.008054    Training error rate: 0.000000
==> Total training loss: 13.871687    Total training error rate: 0.126000
==> Testing Epoch: 92
0.000000/100.000000 ==> Testing loss: 1.174032    Testing error rate: 29.000000
50.000000/100.000000 ==> Testing loss: 1.315701    Testing error rate: 28.000000
==> Total testing loss: 101.778790    Total testing error rate: 24.290000
==> Set learning rate: 0.001000
==> Training Epoch: 93
0.000000/1000.000000 ==> Training loss: 0.013595    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.012435    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.008564    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.006948    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.051108    Training error rate: 2.000000
250.000000/1000.000000 ==> Training loss: 0.007998    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.024094    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.051867    Training error rate: 2.000000
400.000000/1000.000000 ==> Training loss: 0.010582    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.011777    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.017465    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.022841    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.006194    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.006303    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.012422    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.017523    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.006973    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.022107    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.021219    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.012436    Training error rate: 0.000000
==> Total training loss: 13.864002    Total training error rate: 0.122000
==> Testing Epoch: 93
0.000000/100.000000 ==> Testing loss: 1.180704    Testing error rate: 28.000000
50.000000/100.000000 ==> Testing loss: 1.308788    Testing error rate: 27.000000
==> Total testing loss: 101.743313    Total testing error rate: 24.130000
==> Set learning rate: 0.001000
==> Training Epoch: 94
0.000000/1000.000000 ==> Training loss: 0.009830    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.043576    Training error rate: 2.000000
100.000000/1000.000000 ==> Training loss: 0.010259    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.013935    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.005238    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.066249    Training error rate: 2.000000
300.000000/1000.000000 ==> Training loss: 0.010850    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.016304    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.016347    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.009824    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.013601    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.005106    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.004567    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.013878    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.030935    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.004176    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.020371    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.005194    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.004487    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.013954    Training error rate: 0.000000
==> Total training loss: 13.524773    Total training error rate: 0.126000
==> Testing Epoch: 94
0.000000/100.000000 ==> Testing loss: 1.107116    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.283884    Testing error rate: 26.000000
==> Total testing loss: 100.742136    Total testing error rate: 23.940000
==> Set learning rate: 0.001000
==> Training Epoch: 95
0.000000/1000.000000 ==> Training loss: 0.010138    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.007540    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.009515    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.009117    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.009222    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.009817    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.007380    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.008174    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.008046    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.013050    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.008717    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.006817    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.011851    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.017521    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.018310    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.006457    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.009458    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.006836    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.008594    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.020276    Training error rate: 0.000000
==> Total training loss: 12.962695    Total training error rate: 0.100000
==> Testing Epoch: 95
0.000000/100.000000 ==> Testing loss: 1.227621    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.283942    Testing error rate: 26.000000
==> Total testing loss: 101.739848    Total testing error rate: 24.010000
==> Set learning rate: 0.001000
==> Training Epoch: 96
0.000000/1000.000000 ==> Training loss: 0.005832    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.015280    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.010386    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.010063    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.006531    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.023513    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.017962    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.012639    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.012433    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.009242    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.012459    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.018688    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.011253    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.012233    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.011576    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.009166    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.019024    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.010805    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.009461    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.036569    Training error rate: 0.000000
==> Total training loss: 13.331242    Total training error rate: 0.110000
==> Testing Epoch: 96
0.000000/100.000000 ==> Testing loss: 1.198633    Testing error rate: 29.000000
50.000000/100.000000 ==> Testing loss: 1.314135    Testing error rate: 27.000000
==> Total testing loss: 102.313311    Total testing error rate: 24.260000
==> Set learning rate: 0.001000
==> Training Epoch: 97
0.000000/1000.000000 ==> Training loss: 0.008593    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.006280    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.019864    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.005701    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.008078    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.008205    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.004292    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.006758    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.009898    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.007626    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.008123    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.009525    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.030689    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.003620    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.007902    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.011448    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.010588    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.021125    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.012903    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.007008    Training error rate: 0.000000
==> Total training loss: 12.795126    Total training error rate: 0.114000
==> Testing Epoch: 97
0.000000/100.000000 ==> Testing loss: 1.152485    Testing error rate: 26.000000
50.000000/100.000000 ==> Testing loss: 1.321270    Testing error rate: 27.000000
==> Total testing loss: 101.335012    Total testing error rate: 24.110000
==> Set learning rate: 0.001000
==> Training Epoch: 98
0.000000/1000.000000 ==> Training loss: 0.013918    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.013657    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.004649    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.017768    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.009277    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.007992    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.020632    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.012889    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.011903    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.008403    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.007300    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.019146    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.013468    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.007616    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.018537    Training error rate: 0.000000
750.000000/1000.000000 ==> Training loss: 0.006415    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.007639    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.006948    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.007105    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.015724    Training error rate: 0.000000
==> Total training loss: 12.180625    Total training error rate: 0.110000
==> Testing Epoch: 98
0.000000/100.000000 ==> Testing loss: 1.196205    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.337509    Testing error rate: 28.000000
==> Total testing loss: 102.436868    Total testing error rate: 24.210000
==> Set learning rate: 0.001000
==> Training Epoch: 99
0.000000/1000.000000 ==> Training loss: 0.010115    Training error rate: 0.000000
50.000000/1000.000000 ==> Training loss: 0.015717    Training error rate: 0.000000
100.000000/1000.000000 ==> Training loss: 0.014516    Training error rate: 0.000000
150.000000/1000.000000 ==> Training loss: 0.006877    Training error rate: 0.000000
200.000000/1000.000000 ==> Training loss: 0.001917    Training error rate: 0.000000
250.000000/1000.000000 ==> Training loss: 0.008101    Training error rate: 0.000000
300.000000/1000.000000 ==> Training loss: 0.007465    Training error rate: 0.000000
350.000000/1000.000000 ==> Training loss: 0.004764    Training error rate: 0.000000
400.000000/1000.000000 ==> Training loss: 0.007138    Training error rate: 0.000000
450.000000/1000.000000 ==> Training loss: 0.008207    Training error rate: 0.000000
500.000000/1000.000000 ==> Training loss: 0.024953    Training error rate: 0.000000
550.000000/1000.000000 ==> Training loss: 0.003358    Training error rate: 0.000000
600.000000/1000.000000 ==> Training loss: 0.005247    Training error rate: 0.000000
650.000000/1000.000000 ==> Training loss: 0.004661    Training error rate: 0.000000
700.000000/1000.000000 ==> Training loss: 0.087557    Training error rate: 2.000000
750.000000/1000.000000 ==> Training loss: 0.006608    Training error rate: 0.000000
800.000000/1000.000000 ==> Training loss: 0.014744    Training error rate: 0.000000
850.000000/1000.000000 ==> Training loss: 0.008611    Training error rate: 0.000000
900.000000/1000.000000 ==> Training loss: 0.019031    Training error rate: 0.000000
950.000000/1000.000000 ==> Training loss: 0.032041    Training error rate: 2.000000
==> Total training loss: 12.831118    Total training error rate: 0.124000
==> Testing Epoch: 99
0.000000/100.000000 ==> Testing loss: 1.206783    Testing error rate: 27.000000
50.000000/100.000000 ==> Testing loss: 1.307430    Testing error rate: 28.000000
==> Total testing loss: 101.285164    Total testing error rate: 24.190000
